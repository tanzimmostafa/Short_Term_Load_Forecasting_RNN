{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Initial Part Constant For All Models"
      ],
      "metadata": {
        "id": "ADJcydj9-8E3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHJ6DRcUq4j6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBuos30wsaHV",
        "outputId": "9a761306-caa3-4c3f-cfa4-78041b67b11f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to your CSV file\n",
        "csv_file_path = '/content/drive/MyDrive/IS_STLF_Dataset_2012_2015/ERCOT_2012_to_2015.csv'"
      ],
      "metadata": {
        "id": "5Vk_QflXt_Md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2: Finding best hyperparameters/ architecture"
      ],
      "metadata": {
        "id": "O9NtlfL199MH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset into a DataFrame\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "nYIXw8lE9-eL",
        "outputId": "5a1b7cd9-8d98-4d41-cfa9-13e75cd88b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Date  Day of Week(0-6)  Day of the Month(1-31)  \\\n",
              "0  1/1/2012                 6                       1   \n",
              "1  1/1/2012                 6                       1   \n",
              "2  1/1/2012                 6                       1   \n",
              "3  1/1/2012                 6                       1   \n",
              "4  1/1/2012                 6                       1   \n",
              "\n",
              "   Month of the Year(1-12)  Time of Day(0-23)  Holidays  Humidity  \\\n",
              "0                        1                  1         1     34.89   \n",
              "1                        1                  2         1     37.89   \n",
              "2                        1                  3         1     46.46   \n",
              "3                        1                  4         1     54.48   \n",
              "4                        1                  5         1     63.22   \n",
              "\n",
              "   Temperature   Load WEST  \n",
              "0         13.2  849.000892  \n",
              "1         12.0  845.097364  \n",
              "2         10.2  840.902849  \n",
              "3          8.4  845.452257  \n",
              "4          6.6  862.369386  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d69de10-67e5-4b6e-ad04-5ff0ffb06efa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Day of Week(0-6)</th>\n",
              "      <th>Day of the Month(1-31)</th>\n",
              "      <th>Month of the Year(1-12)</th>\n",
              "      <th>Time of Day(0-23)</th>\n",
              "      <th>Holidays</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Load WEST</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/1/2012</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34.89</td>\n",
              "      <td>13.2</td>\n",
              "      <td>849.000892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/1/2012</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>37.89</td>\n",
              "      <td>12.0</td>\n",
              "      <td>845.097364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/1/2012</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>46.46</td>\n",
              "      <td>10.2</td>\n",
              "      <td>840.902849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/1/2012</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>54.48</td>\n",
              "      <td>8.4</td>\n",
              "      <td>845.452257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/1/2012</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>63.22</td>\n",
              "      <td>6.6</td>\n",
              "      <td>862.369386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d69de10-67e5-4b6e-ad04-5ff0ffb06efa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2d69de10-67e5-4b6e-ad04-5ff0ffb06efa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2d69de10-67e5-4b6e-ad04-5ff0ffb06efa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fe3301a6-d331-4f5e-88fa-80d41385baa5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fe3301a6-d331-4f5e-88fa-80d41385baa5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fe3301a6-d331-4f5e-88fa-80d41385baa5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features and target variable\n",
        "features = ['Day of Week(0-6)', 'Day of the Month(1-31)', 'Month of the Year(1-12)', 'Time of Day(0-23)', 'Holidays', 'Humidity', 'Temperature']\n",
        "target_variable = 'Load WEST'\n",
        "data = df[['Day of Week(0-6)', 'Day of the Month(1-31)', 'Month of the Year(1-12)', 'Time of Day(0-23)', 'Holidays', 'Humidity', 'Temperature', 'Load WEST']]"
      ],
      "metadata": {
        "id": "dxrylMNT-Icl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize data using Min-Max normalization\n",
        "scaler = MinMaxScaler()\n",
        "data_normalized = scaler.fit_transform(data)"
      ],
      "metadata": {
        "id": "z9NQ1PHE-K-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(data_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10iodNh2-Nzp",
        "outputId": "dbf01ca8-9e6e-4489-8958-7068ceb05a87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_normalized.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e889d03d-03de-421b-f063-e584f219d955",
        "id": "fw9BN_TN-fnh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35064, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2015 starts fromrow 26304\n",
        "#checking\n",
        "data.iloc[26303]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea1d16e-603a-4fa6-8176-061889f4eb2c",
        "id": "bwItuCOJ-fni"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Day of Week(0-6)              3.00000\n",
              "Day of the Month(1-31)        1.00000\n",
              "Month of the Year(1-12)       1.00000\n",
              "Time of Day(0-23)             0.00000\n",
              "Holidays                      1.00000\n",
              "Humidity                     77.15000\n",
              "Temperature                   1.20000\n",
              "Load WEST                  1504.43762\n",
              "Name: 26303, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_normalized[26303]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cfc3273-2696-4c0e-9f90-d9da4e3595ad",
        "id": "IVJkZAnc-fni"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5       , 0.        , 0.        , 0.        , 1.        ,\n",
              "       0.75412989, 0.20517928, 0.69694446])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set=data_normalized[:26303]\n",
        "test_set=data_normalized[26303:]"
      ],
      "metadata": {
        "id": "D6n5paBT-fni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_set.shape)\n",
        "print(test_set.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3db8933e-1d47-4056-a97a-b24297a6ee71",
        "id": "i3E9UN8B-fni"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26303, 8)\n",
            "(8761, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to prepare sequences for LSTM\n",
        "def prepare_sequences(data, look_back):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - look_back):\n",
        "        X.append(data[i:(i + look_back), :])\n",
        "        y.append(data[i + look_back, -1])  # Assuming Load WEST is the last column\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Set the look-back window\n",
        "look_back = 12 # Adjust this value based on your analysis"
      ],
      "metadata": {
        "id": "wdYfAwjK-tP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare sequences for train set\n",
        "X_train_I, y_train_I = prepare_sequences(train_set, look_back)"
      ],
      "metadata": {
        "id": "cXIQpqxj-0OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare sequences for test set\n",
        "X_test, y_test = prepare_sequences(test_set, look_back)"
      ],
      "metadata": {
        "id": "0TlX-4ok-0OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_I.shape)\n",
        "print(y_train_I.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f263a59-0fc1-4593-e167-00adb08c2665",
        "id": "95jqsT8L-0OS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26291, 12, 8)\n",
            "(26291,)\n",
            "(8749, 12, 8)\n",
            "(8749,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training, validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_I, y_train_I, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "T2HiUgjl-0OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "925d1ad8-f9fa-4f55-feeb-14d4ee05781f",
        "id": "sTXkkW1X-0OT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21032, 12, 8)\n",
            "(21032,)\n",
            "(5259, 12, 8)\n",
            "(5259,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43120e78-743b-479c-d328-95cbb0e5066f",
        "id": "ZE0tkMUp-0OT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRXQ4Gtn_khd",
        "outputId": "19b184ca-6d24-47db-c676-7646d395d57e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/128.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m92.2/128.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.14.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.11.17)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.6 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Assuming you have X_train, y_train, X_val, y_val defined\n",
        "\n",
        "# Function to build the model\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Tune the number of LSTM units\n",
        "    model.add(GRU(units=hp.Int('units', min_value=30, max_value=80, step=10),\n",
        "                   return_sequences=True,\n",
        "                   input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "\n",
        "    # Tune the number of intermediate LSTM layers\n",
        "    for _ in range(hp.Int('num_layers', min_value=1, max_value=5)):\n",
        "        model.add(GRU(units=hp.Int('units', min_value=30, max_value=80, step=10), return_sequences=True))\n",
        "\n",
        "    # Manually set return_sequences=False for the last LSTM layer\n",
        "    model.add(GRU(units=hp.Int('units_last', min_value=30, max_value=80, step=10), return_sequences=False))\n",
        "\n",
        "    # Dense layer for final prediction\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    # Choose between Adam and Nadam optimizers\n",
        "    optimizer_choice = hp.Choice('optimizer', ['adam', 'nadam'])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=optimizer_choice, loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define the tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=10,  # Adjust as needed\n",
        "    executions_per_trial=1,\n",
        "    directory='my_tuner_directory',\n",
        "    project_name='lstm_tuning'\n",
        ")\n",
        "\n",
        "# Early stopping to stop training when the validation loss doesn't improve\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Perform the search\n",
        "tuner.search(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Build the final model with the best hyperparameters\n",
        "final_model = build_model(best_hps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmb-wdi9DBQS",
        "outputId": "1645665e-c784-4927-fc83-1a3617f7fffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 17m 15s]\n",
            "val_loss: 0.0001335972046945244\n",
            "\n",
            "Best val_loss So Far: 0.00010635465878294781\n",
            "Total elapsed time: 02h 17m 53s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a903438-g6Mu",
        "outputId": "8d6fec29-bf15-47da-aac6-5117d5e68b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters at 0x7b7f70115570>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(f\"Number of Units: {best_hps.get('units')}\")\n",
        "print(f\"Number of Intermediate Layers: {best_hps.get('num_layers')}\")\n",
        "print(f\"Number of Units in Last Layer: {best_hps.get('units_last')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YJHaEux8Ygc",
        "outputId": "1dab7148-9238-4076-b923-435850f31058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters:\n",
            "Number of Units: 50\n",
            "Number of Intermediate Layers: 4\n",
            "Number of Units in Last Layer: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(best_hps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UktZiwLJl1g8",
        "outputId": "0c031ddb-3691-4b07-f58a-a4d21aed23ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume you have obtained best_hps as mentioned before\n",
        "\n",
        "# Print all attributes and their values\n",
        "for key, value in best_hps.__dict__.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cLPhcv8lygW",
        "outputId": "eefa3461-c99d-41a8-80f9-435cfad94028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_name_scopes: []\n",
            "_conditions: []\n",
            "_hps: defaultdict(<class 'list'>, {'units': [Int(name: 'units', min_value: 30, max_value: 80, step: 10, sampling: linear, default: 30)], 'num_layers': [Int(name: 'num_layers', min_value: 1, max_value: 5, step: 1, sampling: linear, default: 1)], 'units_last': [Int(name: 'units_last', min_value: 30, max_value: 80, step: 10, sampling: linear, default: 30)], 'optimizer': [Choice(name: 'optimizer', values: ['adam', 'nadam'], ordered: False, default: adam)]})\n",
            "_space: [Int(name: 'units', min_value: 30, max_value: 80, step: 10, sampling: linear, default: 30), Int(name: 'num_layers', min_value: 1, max_value: 5, step: 1, sampling: linear, default: 1), Int(name: 'units_last', min_value: 30, max_value: 80, step: 10, sampling: linear, default: 30), Choice(name: 'optimizer', values: ['adam', 'nadam'], ordered: False, default: adam)]\n",
            "values: {'units': 50, 'num_layers': 4, 'units_last': 30, 'optimizer': 'adam'}\n",
            "active_scopes: []\n",
            "inactive_scopes: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the final model\n",
        "history = final_model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_loss = final_model.evaluate(X_test, y_test)\n",
        "\n",
        "# You can access the best model using the 'best_model' variable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r15IYEtQxLVI",
        "outputId": "d6fedc40-7171-4d49-dbe5-5ad5ed174c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "658/658 [==============================] - 51s 56ms/step - loss: 0.0046 - val_loss: 4.7183e-04\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 36s 54ms/step - loss: 4.1888e-04 - val_loss: 3.1827e-04\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 35s 53ms/step - loss: 3.9140e-04 - val_loss: 5.0565e-04\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 35s 53ms/step - loss: 3.8435e-04 - val_loss: 2.7627e-04\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 34s 52ms/step - loss: 3.4554e-04 - val_loss: 3.0566e-04\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 34s 52ms/step - loss: 2.9979e-04 - val_loss: 3.7224e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 34s 52ms/step - loss: 2.8926e-04 - val_loss: 2.9398e-04\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 34s 51ms/step - loss: 2.9267e-04 - val_loss: 2.5441e-04\n",
            "Epoch 9/100\n",
            "658/658 [==============================] - 34s 51ms/step - loss: 2.4841e-04 - val_loss: 2.2119e-04\n",
            "Epoch 10/100\n",
            "658/658 [==============================] - 34s 52ms/step - loss: 2.5563e-04 - val_loss: 3.5247e-04\n",
            "Epoch 11/100\n",
            "658/658 [==============================] - 35s 53ms/step - loss: 2.4413e-04 - val_loss: 3.1879e-04\n",
            "Epoch 12/100\n",
            "658/658 [==============================] - 34s 52ms/step - loss: 2.1663e-04 - val_loss: 2.8048e-04\n",
            "Epoch 13/100\n",
            "658/658 [==============================] - 35s 53ms/step - loss: 2.0043e-04 - val_loss: 2.2052e-04\n",
            "Epoch 14/100\n",
            "658/658 [==============================] - 35s 54ms/step - loss: 2.2899e-04 - val_loss: 2.3952e-04\n",
            "Epoch 15/100\n",
            "658/658 [==============================] - 35s 53ms/step - loss: 1.9934e-04 - val_loss: 1.6722e-04\n",
            "Epoch 16/100\n",
            "658/658 [==============================] - 35s 53ms/step - loss: 1.9876e-04 - val_loss: 1.8904e-04\n",
            "Epoch 17/100\n",
            "658/658 [==============================] - 35s 53ms/step - loss: 1.9348e-04 - val_loss: 2.3059e-04\n",
            "Epoch 18/100\n",
            "658/658 [==============================] - 34s 52ms/step - loss: 1.8214e-04 - val_loss: 1.6242e-04\n",
            "Epoch 19/100\n",
            "658/658 [==============================] - 34s 52ms/step - loss: 1.8152e-04 - val_loss: 2.6994e-04\n",
            "Epoch 20/100\n",
            "658/658 [==============================] - 34s 51ms/step - loss: 1.8018e-04 - val_loss: 1.5722e-04\n",
            "Epoch 21/100\n",
            "658/658 [==============================] - 34s 51ms/step - loss: 1.6970e-04 - val_loss: 1.7541e-04\n",
            "Epoch 22/100\n",
            "658/658 [==============================] - 34s 52ms/step - loss: 1.7250e-04 - val_loss: 1.6915e-04\n",
            "Epoch 23/100\n",
            "658/658 [==============================] - 35s 52ms/step - loss: 1.6917e-04 - val_loss: 1.8066e-04\n",
            "Epoch 24/100\n",
            "658/658 [==============================] - 35s 53ms/step - loss: 1.5186e-04 - val_loss: 1.4421e-04\n",
            "Epoch 25/100\n",
            "658/658 [==============================] - 35s 53ms/step - loss: 1.6313e-04 - val_loss: 1.3118e-04\n",
            "Epoch 26/100\n",
            "658/658 [==============================] - 35s 53ms/step - loss: 1.5207e-04 - val_loss: 1.5325e-04\n",
            "Epoch 27/100\n",
            "658/658 [==============================] - 35s 53ms/step - loss: 1.4872e-04 - val_loss: 1.7646e-04\n",
            "Epoch 28/100\n",
            "658/658 [==============================] - 35s 53ms/step - loss: 1.4886e-04 - val_loss: 1.7935e-04\n",
            "Epoch 29/100\n",
            "658/658 [==============================] - 35s 53ms/step - loss: 1.3225e-04 - val_loss: 1.4669e-04\n",
            "Epoch 30/100\n",
            "658/658 [==============================] - 35s 53ms/step - loss: 1.4276e-04 - val_loss: 1.3836e-04\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 1.1976e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fE0a2yxmcOk",
        "outputId": "9bb70c93-ef35-43ff-9c20-cf331118c3d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00011975849338341504"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXtBcDT2jFlk",
        "outputId": "019caeeb-384a-44c7-cd04-335cc29d2916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8749, 12, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[:, -1, :].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHY4f0BriVa9",
        "outputId": "f708daac-6a87-41ea-9c56-36580ce525f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8749, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "predictions = final_model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g8TY6-MtXDh",
        "outputId": "fba66701-51bc-4dbf-d721-32437410dc6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "274/274 [==============================] - 6s 14ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN1UfC79tfbE",
        "outputId": "adc317eb-680a-43d0-9e74-40433f66f69a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8749, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Drqf-P4ht4lU",
        "outputId": "cb8bfd0c-2a0e-40f6-c8bb-259cda47c951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8749,)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Invert the predictions and actual values to compare with the original scale\n",
        "predictions_original = scaler.inverse_transform(np.concatenate((X_test[:, -1, :-1], predictions), axis=1))[:, -1]\n",
        "y_test_original = scaler.inverse_transform(np.concatenate((X_test[:, -1, :-1], y_test.reshape(-1, 1)), axis=1))[:, -1]\n"
      ],
      "metadata": {
        "id": "dd1jV5HDtOej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
        "mape = mean_absolute_percentage_error(y_test_original, predictions_original)\n",
        "r2 = r2_score(y_test_original, predictions_original)\n",
        "\n",
        "print(f'Mean Absolute Percentage Error (MAPE): {mape * 100:.2f}%')\n",
        "print(f'R-squared (R2): {r2:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A0JjK3QgrPl",
        "outputId": "58f8a521-7d4e-4c54-f730-ba78fea9281e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Percentage Error (MAPE): 0.90%\n",
            "R-squared (R2): 0.9966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "mae = mean_absolute_error(y_test_original, predictions_original)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_original, predictions_original))\n",
        "\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL_tsTAckhKY",
        "outputId": "33768b8a-9b11-4a05-8fe9-a19117bf493a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 10.072336946314838\n",
            "Root Mean Squared Error (RMSE): 13.7020983989227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test_original, predictions_original)\n",
        "print(\"Mean Squared Error (MSE):\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY3QeXPvkkZy",
        "outputId": "0305d63e-cfcd-4d39-ca6d-d1e2dce39232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 187.74750053376002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RguQki_2FaKD",
        "outputId": "c7413dfb-bc42-4f1b-c0e4-5bc4c41e16d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_7 (GRU)                 (None, 12, 50)            9000      \n",
            "                                                                 \n",
            " gru_8 (GRU)                 (None, 12, 50)            15300     \n",
            "                                                                 \n",
            " gru_9 (GRU)                 (None, 12, 50)            15300     \n",
            "                                                                 \n",
            " gru_10 (GRU)                (None, 12, 50)            15300     \n",
            "                                                                 \n",
            " gru_11 (GRU)                (None, 12, 50)            15300     \n",
            "                                                                 \n",
            " gru_12 (GRU)                (None, 30)                7380      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 77611 (303.17 KB)\n",
            "Trainable params: 77611 (303.17 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, layer in enumerate(final_model.layers):\n",
        "    print(f\"Layer {i+1}: {layer.name} - Type: {type(layer).__name__}\")\n",
        "    if hasattr(layer, 'units'):\n",
        "        print(f\"Number of Neurons: {layer.units}\")\n",
        "    print(\"-----------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLCpS7iVFmbG",
        "outputId": "362f3f48-4bcf-420a-d71f-586bce06c732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1: gru_7 - Type: GRU\n",
            "Number of Neurons: 50\n",
            "-----------------------------------\n",
            "Layer 2: gru_8 - Type: GRU\n",
            "Number of Neurons: 50\n",
            "-----------------------------------\n",
            "Layer 3: gru_9 - Type: GRU\n",
            "Number of Neurons: 50\n",
            "-----------------------------------\n",
            "Layer 4: gru_10 - Type: GRU\n",
            "Number of Neurons: 50\n",
            "-----------------------------------\n",
            "Layer 5: gru_11 - Type: GRU\n",
            "Number of Neurons: 50\n",
            "-----------------------------------\n",
            "Layer 6: gru_12 - Type: GRU\n",
            "Number of Neurons: 30\n",
            "-----------------------------------\n",
            "Layer 7: dense_1 - Type: Dense\n",
            "Number of Neurons: 1\n",
            "-----------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Extract loss values from the history object\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Plot the loss curves\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "plt.plot(epochs, train_loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "C9B5JLCz8sZ2",
        "outputId": "754f5d12-7a79-4b71-a5cf-74b86d1405d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 3: Using Best Hyperparameters to obtain optimum look-back window"
      ],
      "metadata": {
        "id": "Cm5Y6ufo_JU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset into a DataFrame\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "6de41ad9-ab07-4da9-fa03-3d8d49ddda3e",
        "id": "Fg2_uxYuLQ25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Date  Day of Week(0-6)  Day of the Month(1-31)  \\\n",
              "0  1/1/2012                 6                       1   \n",
              "1  1/1/2012                 6                       1   \n",
              "2  1/1/2012                 6                       1   \n",
              "3  1/1/2012                 6                       1   \n",
              "4  1/1/2012                 6                       1   \n",
              "\n",
              "   Month of the Year(1-12)  Time of Day(0-23)  Holidays  Humidity  \\\n",
              "0                        1                  1         1     34.89   \n",
              "1                        1                  2         1     37.89   \n",
              "2                        1                  3         1     46.46   \n",
              "3                        1                  4         1     54.48   \n",
              "4                        1                  5         1     63.22   \n",
              "\n",
              "   Temperature   Load WEST  \n",
              "0         13.2  849.000892  \n",
              "1         12.0  845.097364  \n",
              "2         10.2  840.902849  \n",
              "3          8.4  845.452257  \n",
              "4          6.6  862.369386  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b093d05-ee26-4c96-ac7d-33b0649dc0d5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Day of Week(0-6)</th>\n",
              "      <th>Day of the Month(1-31)</th>\n",
              "      <th>Month of the Year(1-12)</th>\n",
              "      <th>Time of Day(0-23)</th>\n",
              "      <th>Holidays</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Load WEST</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/1/2012</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34.89</td>\n",
              "      <td>13.2</td>\n",
              "      <td>849.000892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/1/2012</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>37.89</td>\n",
              "      <td>12.0</td>\n",
              "      <td>845.097364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/1/2012</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>46.46</td>\n",
              "      <td>10.2</td>\n",
              "      <td>840.902849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/1/2012</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>54.48</td>\n",
              "      <td>8.4</td>\n",
              "      <td>845.452257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/1/2012</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>63.22</td>\n",
              "      <td>6.6</td>\n",
              "      <td>862.369386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b093d05-ee26-4c96-ac7d-33b0649dc0d5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6b093d05-ee26-4c96-ac7d-33b0649dc0d5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6b093d05-ee26-4c96-ac7d-33b0649dc0d5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a8172ebb-730f-42b9-a91c-fe7355538c16\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a8172ebb-730f-42b9-a91c-fe7355538c16')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a8172ebb-730f-42b9-a91c-fe7355538c16 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features and target variable\n",
        "features = ['Day of Week(0-6)', 'Day of the Month(1-31)', 'Month of the Year(1-12)', 'Time of Day(0-23)', 'Holidays', 'Humidity', 'Temperature']\n",
        "target_variable = 'Load WEST'\n",
        "data = df[['Day of Week(0-6)', 'Day of the Month(1-31)', 'Month of the Year(1-12)', 'Time of Day(0-23)', 'Holidays', 'Humidity', 'Temperature', 'Load WEST']]"
      ],
      "metadata": {
        "id": "RaIeEONJLQ3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize data using Min-Max normalization\n",
        "scaler = MinMaxScaler()\n",
        "data_normalized = scaler.fit_transform(data)"
      ],
      "metadata": {
        "id": "LGt7rTZaLQ3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(data_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "155b18c6-b614-4193-fd6e-fc3699319392",
        "id": "XD-Gd__pLQ3M"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_normalized.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f916c3e2-c52d-4f69-b6b9-6f8c7fa3a9e1",
        "id": "ZXHKmZy-LQ3M"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35064, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2015 starts from row 26304\n",
        "#checking\n",
        "data.iloc[26303]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "052d97d3-5208-4071-b031-6822ea32f061",
        "id": "hfyoqRqfLQ3N"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Day of Week(0-6)              3.00000\n",
              "Day of the Month(1-31)        1.00000\n",
              "Month of the Year(1-12)       1.00000\n",
              "Time of Day(0-23)             0.00000\n",
              "Holidays                      1.00000\n",
              "Humidity                     77.15000\n",
              "Temperature                   1.20000\n",
              "Load WEST                  1504.43762\n",
              "Name: 26303, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_normalized[26303]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23b096d7-34d6-4240-81d9-91df07e069f6",
        "id": "lwyrrD3pLQ3N"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5       , 0.        , 0.        , 0.        , 1.        ,\n",
              "       0.75412989, 0.20517928, 0.69694446])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set=data_normalized[:26303]\n",
        "test_set=data_normalized[26303:]"
      ],
      "metadata": {
        "id": "EF_MZhXvLQ3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_set.shape)\n",
        "print(test_set.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72d251ef-ca33-4d81-f5e0-ebe91e1f8666",
        "id": "LA_cqRQ5LQ3O"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26303, 8)\n",
            "(8761, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to prepare sequences for LSTM\n",
        "def prepare_sequences(data, look_back):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - look_back):\n",
        "        X.append(data[i:(i + look_back), :])\n",
        "        y.append(data[i + look_back, -1])  # Assuming Load WEST is the last column\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Set the look-back window\n",
        "# look_back = 12 # Adjust this value based on your analysis"
      ],
      "metadata": {
        "id": "PFLKN4T6AhEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cce7aa41-c3df-43ae-fb0f-1d700756bf53",
        "id": "abkX7ZG7JQ-b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.14.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.11.17)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.6 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best GRU Model Architecture\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Function to build the model with specific hyperparameters\n",
        "def build_model_with_params(units, num_layers, units_last, input_shape):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add the first GRU layer\n",
        "    model.add(GRU(units=units, return_sequences=True, input_shape=input_shape))\n",
        "\n",
        "    # Add intermediate GRU layers\n",
        "    for _ in range(num_layers):\n",
        "        model.add(GRU(units=units, return_sequences=True))\n",
        "\n",
        "    # Add the last GRU layer with return_sequences=False\n",
        "    model.add(GRU(units=units_last, return_sequences=False))\n",
        "\n",
        "    # Add a Dense layer for final prediction\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Best Hyperparameters obtained from tuning\n",
        "best_units = 50\n",
        "best_num_layers = 4\n",
        "best_units_last = 30\n",
        "\n",
        "# Input shape based on your data\n",
        "input_shape = (12, 8)  # Update features_count based on your data\n",
        "\n",
        "# Build the model with best hyperparameters\n",
        "best_model = build_model_with_params(units=best_units, num_layers=best_num_layers, units_last=best_units_last, input_shape=input_shape)\n",
        "\n",
        "# Print model summary\n",
        "best_model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp5ys9D_CVj2",
        "outputId": "0318d3b7-682c-462f-fd7f-076d094b6130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_13 (GRU)                (None, 12, 50)            9000      \n",
            "                                                                 \n",
            " gru_14 (GRU)                (None, 12, 50)            15300     \n",
            "                                                                 \n",
            " gru_15 (GRU)                (None, 12, 50)            15300     \n",
            "                                                                 \n",
            " gru_16 (GRU)                (None, 12, 50)            15300     \n",
            "                                                                 \n",
            " gru_17 (GRU)                (None, 12, 50)            15300     \n",
            "                                                                 \n",
            " gru_18 (GRU)                (None, 30)                7380      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 77611 (303.17 KB)\n",
            "Trainable params: 77611 (303.17 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "# Function to build the model with specific hyperparameters\n",
        "def build_model_with_params(units, num_layers, units_last, input_shape):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add the first GRU layer\n",
        "    model.add(GRU(units=units, return_sequences=True, input_shape=input_shape))\n",
        "\n",
        "    # Add intermediate GRU layers\n",
        "    for _ in range(num_layers):\n",
        "        model.add(GRU(units=units, return_sequences=True))\n",
        "\n",
        "    # Add the last GRU layer with return_sequences=False\n",
        "    model.add(GRU(units=units_last, return_sequences=False))\n",
        "\n",
        "    # Add a Dense layer for final prediction\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Best Hyperparameters obtained from tuning\n",
        "best_units = 50\n",
        "best_num_layers = 4\n",
        "best_units_last = 30\n",
        "\n",
        "# Input shape based on your data\n",
        "# input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "\n",
        "# Automate for different look-back windows\n",
        "look_back_values = [2, 4 ,6, 8 ,10 ,12 ,14 ,16 ,18 ,20 , 22, 24]\n",
        "\n",
        "for look_back in look_back_values:\n",
        "    #X, y = prepare_sequences(data_normalized, look_back)\n",
        "\n",
        "    # Split the data into training, validation, and testing sets\n",
        "    #X_train_current, X_temp, y_train_current, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "    #X_val_current, X_test, y_val_current, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "    # Prepare sequences for train set\n",
        "    X_train_I, y_train_I = prepare_sequences(train_set, look_back)\n",
        "    # Prepare sequences for test set\n",
        "    X_test, y_test = prepare_sequences(test_set, look_back)\n",
        "\n",
        "    # Split the data into training, validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_I, y_train_I, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Build the model with specific hyperparameters\n",
        "    current_model = build_model_with_params(units=best_units, num_layers=best_num_layers, units_last=best_units_last, input_shape=(X_train.shape[1], X_train.shape[2]))\n",
        "\n",
        "    # Prepare sequences with the current look_back\n",
        "   # X_train_current, y_train_current = prepare_sequences(X_train, look_back)\n",
        "   # X_val_current, y_val_current = prepare_sequences(X_val, look_back)\n",
        "\n",
        "    # Train the model with EarlyStopping callback\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    current_model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_test_pred = current_model.predict(X_test)\n",
        "\n",
        "    # Invert the predictions and actual values to compare with the original scale\n",
        "    predictions_original = scaler.inverse_transform(np.concatenate((X_test[:, -1, :-1], y_test_pred.reshape(-1, 1)), axis=1))[:, -1]\n",
        "    y_test_original = scaler.inverse_transform(np.concatenate((X_test[:, -1, :-1], y_test.reshape(-1, 1)), axis=1))[:, -1]\n",
        "\n",
        "    # Calculate and print metrics\n",
        "    mse = mean_squared_error(y_test_original, predictions_original)\n",
        "    mae = mean_absolute_error(y_test_original, predictions_original)\n",
        "    mape = mean_absolute_percentage_error(y_test_original, predictions_original)*100\n",
        "    rmse = np.sqrt(mse)\n",
        "    #r2 = r2_score(y_test_original, predictions_original)\n",
        "\n",
        "    print(f\"Look Back: {look_back}\")\n",
        "    print(f\"MSE: {mse}\")\n",
        "    print(f\"MAE: {mae}\")\n",
        "    print(f\"MAPE: {mape}\")\n",
        "    print(f\"RMSE: {rmse}\")\n",
        "    #print(f\"R2: {r2}\")\n",
        "    print(\"--------------------\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Gn9oydIdBljv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe9faf6-521b-4d36-d139-83b7da3bc7db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "658/658 [==============================] - 29s 24ms/step - loss: 0.0071 - val_loss: 9.1988e-04\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 13s 19ms/step - loss: 5.3365e-04 - val_loss: 3.4852e-04\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 12s 18ms/step - loss: 4.0043e-04 - val_loss: 3.8756e-04\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 12s 18ms/step - loss: 3.8898e-04 - val_loss: 3.2845e-04\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 13s 19ms/step - loss: 3.8225e-04 - val_loss: 6.7509e-04\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 12s 19ms/step - loss: 3.8261e-04 - val_loss: 3.8662e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 11s 17ms/step - loss: 3.6226e-04 - val_loss: 4.5833e-04\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 13s 19ms/step - loss: 3.6134e-04 - val_loss: 4.3160e-04\n",
            "Epoch 9/100\n",
            "658/658 [==============================] - 14s 21ms/step - loss: 3.5753e-04 - val_loss: 3.6616e-04\n",
            "274/274 [==============================] - 3s 4ms/step\n",
            "Look Back: 2\n",
            "MSE: 533.0656143113249\n",
            "MAE: 16.766715045001497\n",
            "MAPE: 1.487170641628566\n",
            "RMSE: 23.0882137531539\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "658/658 [==============================] - 34s 29ms/step - loss: 0.0057 - val_loss: 4.8186e-04\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 4.6323e-04 - val_loss: 6.1492e-04\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 4.1615e-04 - val_loss: 3.5532e-04\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 3.7741e-04 - val_loss: 3.4860e-04\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 18s 27ms/step - loss: 3.6337e-04 - val_loss: 4.9186e-04\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 3.7600e-04 - val_loss: 3.4549e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 3.3060e-04 - val_loss: 4.4386e-04\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 3.2493e-04 - val_loss: 2.9477e-04\n",
            "Epoch 9/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 3.0228e-04 - val_loss: 3.0333e-04\n",
            "Epoch 10/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 3.1416e-04 - val_loss: 2.8024e-04\n",
            "Epoch 11/100\n",
            "658/658 [==============================] - 16s 25ms/step - loss: 2.8742e-04 - val_loss: 2.6255e-04\n",
            "Epoch 12/100\n",
            "658/658 [==============================] - 17s 25ms/step - loss: 2.7692e-04 - val_loss: 2.5974e-04\n",
            "Epoch 13/100\n",
            "658/658 [==============================] - 16s 25ms/step - loss: 2.7540e-04 - val_loss: 3.2484e-04\n",
            "Epoch 14/100\n",
            "658/658 [==============================] - 16s 25ms/step - loss: 2.6335e-04 - val_loss: 2.4256e-04\n",
            "Epoch 15/100\n",
            "658/658 [==============================] - 16s 25ms/step - loss: 2.6215e-04 - val_loss: 2.6078e-04\n",
            "Epoch 16/100\n",
            "658/658 [==============================] - 16s 25ms/step - loss: 2.6117e-04 - val_loss: 3.3832e-04\n",
            "Epoch 17/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 2.6004e-04 - val_loss: 2.3227e-04\n",
            "Epoch 18/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 2.5424e-04 - val_loss: 2.4548e-04\n",
            "Epoch 19/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 2.3715e-04 - val_loss: 2.3230e-04\n",
            "Epoch 20/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 2.3065e-04 - val_loss: 2.2332e-04\n",
            "Epoch 21/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 2.2849e-04 - val_loss: 2.1740e-04\n",
            "Epoch 22/100\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 2.1949e-04 - val_loss: 2.3978e-04\n",
            "Epoch 23/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 2.0899e-04 - val_loss: 2.0648e-04\n",
            "Epoch 24/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 2.1091e-04 - val_loss: 2.6398e-04\n",
            "Epoch 25/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 2.0791e-04 - val_loss: 2.0283e-04\n",
            "Epoch 26/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 1.9981e-04 - val_loss: 1.8143e-04\n",
            "Epoch 27/100\n",
            "658/658 [==============================] - 18s 27ms/step - loss: 2.0536e-04 - val_loss: 2.2372e-04\n",
            "Epoch 28/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 1.8239e-04 - val_loss: 1.8539e-04\n",
            "Epoch 29/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 1.8668e-04 - val_loss: 1.8519e-04\n",
            "Epoch 30/100\n",
            "658/658 [==============================] - 17s 25ms/step - loss: 1.8724e-04 - val_loss: 3.0754e-04\n",
            "Epoch 31/100\n",
            "658/658 [==============================] - 16s 25ms/step - loss: 1.7792e-04 - val_loss: 1.7981e-04\n",
            "Epoch 32/100\n",
            "658/658 [==============================] - 16s 25ms/step - loss: 1.7008e-04 - val_loss: 2.0339e-04\n",
            "Epoch 33/100\n",
            "658/658 [==============================] - 16s 25ms/step - loss: 1.6329e-04 - val_loss: 1.7230e-04\n",
            "Epoch 34/100\n",
            "658/658 [==============================] - 16s 25ms/step - loss: 1.6947e-04 - val_loss: 1.6866e-04\n",
            "Epoch 35/100\n",
            "658/658 [==============================] - 16s 25ms/step - loss: 1.6408e-04 - val_loss: 2.3447e-04\n",
            "Epoch 36/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 1.5257e-04 - val_loss: 1.5761e-04\n",
            "Epoch 37/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 1.5501e-04 - val_loss: 1.4184e-04\n",
            "Epoch 38/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 1.5455e-04 - val_loss: 2.7402e-04\n",
            "Epoch 39/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 1.4770e-04 - val_loss: 2.0608e-04\n",
            "Epoch 40/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 1.3942e-04 - val_loss: 1.6910e-04\n",
            "Epoch 41/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 1.4733e-04 - val_loss: 1.4845e-04\n",
            "Epoch 42/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 1.3994e-04 - val_loss: 1.7788e-04\n",
            "274/274 [==============================] - 4s 6ms/step\n",
            "Look Back: 4\n",
            "MSE: 212.09778727252586\n",
            "MAE: 10.743994116348059\n",
            "MAPE: 0.9591468106852663\n",
            "RMSE: 14.56357742014392\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "658/658 [==============================] - 38s 37ms/step - loss: 0.0058 - val_loss: 3.9262e-04\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 22s 33ms/step - loss: 4.2257e-04 - val_loss: 3.4896e-04\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 21s 31ms/step - loss: 4.0735e-04 - val_loss: 3.3495e-04\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 21s 31ms/step - loss: 3.8371e-04 - val_loss: 2.7727e-04\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 3.7503e-04 - val_loss: 2.6780e-04\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 23s 34ms/step - loss: 3.3697e-04 - val_loss: 2.6794e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 22s 33ms/step - loss: 3.3055e-04 - val_loss: 2.5157e-04\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 3.1082e-04 - val_loss: 2.7873e-04\n",
            "Epoch 9/100\n",
            "658/658 [==============================] - 21s 31ms/step - loss: 2.9264e-04 - val_loss: 3.5299e-04\n",
            "Epoch 10/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 2.9205e-04 - val_loss: 2.8168e-04\n",
            "Epoch 11/100\n",
            "658/658 [==============================] - 22s 33ms/step - loss: 2.7967e-04 - val_loss: 2.3342e-04\n",
            "Epoch 12/100\n",
            "658/658 [==============================] - 22s 34ms/step - loss: 2.8033e-04 - val_loss: 2.0537e-04\n",
            "Epoch 13/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 2.5407e-04 - val_loss: 2.1039e-04\n",
            "Epoch 14/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 2.5345e-04 - val_loss: 2.5851e-04\n",
            "Epoch 15/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 2.4776e-04 - val_loss: 1.9637e-04\n",
            "Epoch 16/100\n",
            "658/658 [==============================] - 23s 35ms/step - loss: 2.4124e-04 - val_loss: 2.5482e-04\n",
            "Epoch 17/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 2.3473e-04 - val_loss: 1.8066e-04\n",
            "Epoch 18/100\n",
            "658/658 [==============================] - 21s 31ms/step - loss: 2.3572e-04 - val_loss: 2.6698e-04\n",
            "Epoch 19/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 2.2765e-04 - val_loss: 1.9538e-04\n",
            "Epoch 20/100\n",
            "658/658 [==============================] - 23s 35ms/step - loss: 2.1783e-04 - val_loss: 3.3274e-04\n",
            "Epoch 21/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 2.1065e-04 - val_loss: 1.8368e-04\n",
            "Epoch 22/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 2.1834e-04 - val_loss: 1.6164e-04\n",
            "Epoch 23/100\n",
            "658/658 [==============================] - 20s 31ms/step - loss: 2.0344e-04 - val_loss: 1.9551e-04\n",
            "Epoch 24/100\n",
            "658/658 [==============================] - 21s 31ms/step - loss: 1.9897e-04 - val_loss: 1.9692e-04\n",
            "Epoch 25/100\n",
            "658/658 [==============================] - 23s 35ms/step - loss: 1.9876e-04 - val_loss: 1.7178e-04\n",
            "Epoch 26/100\n",
            "658/658 [==============================] - 21s 33ms/step - loss: 1.8926e-04 - val_loss: 1.8665e-04\n",
            "Epoch 27/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 1.8790e-04 - val_loss: 2.2488e-04\n",
            "274/274 [==============================] - 4s 7ms/step\n",
            "Look Back: 6\n",
            "MSE: 266.57686546589775\n",
            "MAE: 11.997329236433622\n",
            "MAPE: 1.0767904421394816\n",
            "RMSE: 16.327181798029255\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "658/658 [==============================] - 46s 47ms/step - loss: 0.0050 - val_loss: 4.2244e-04\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 27s 41ms/step - loss: 4.8910e-04 - val_loss: 3.2056e-04\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 27s 41ms/step - loss: 3.9352e-04 - val_loss: 4.4641e-04\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 27s 41ms/step - loss: 3.5991e-04 - val_loss: 2.8305e-04\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 26s 40ms/step - loss: 3.3905e-04 - val_loss: 2.4203e-04\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 27s 40ms/step - loss: 3.3408e-04 - val_loss: 2.8446e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 27s 40ms/step - loss: 3.0031e-04 - val_loss: 2.0645e-04\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 27s 41ms/step - loss: 2.5669e-04 - val_loss: 2.8722e-04\n",
            "Epoch 9/100\n",
            "658/658 [==============================] - 26s 40ms/step - loss: 2.5268e-04 - val_loss: 1.7652e-04\n",
            "Epoch 10/100\n",
            "658/658 [==============================] - 26s 40ms/step - loss: 2.3957e-04 - val_loss: 1.9915e-04\n",
            "Epoch 11/100\n",
            "658/658 [==============================] - 27s 40ms/step - loss: 2.3571e-04 - val_loss: 3.6291e-04\n",
            "Epoch 12/100\n",
            "658/658 [==============================] - 27s 41ms/step - loss: 2.3862e-04 - val_loss: 1.8102e-04\n",
            "Epoch 13/100\n",
            "658/658 [==============================] - 27s 40ms/step - loss: 2.4699e-04 - val_loss: 1.7902e-04\n",
            "Epoch 14/100\n",
            "658/658 [==============================] - 27s 41ms/step - loss: 2.1072e-04 - val_loss: 2.8340e-04\n",
            "274/274 [==============================] - 4s 8ms/step\n",
            "Look Back: 8\n",
            "MSE: 273.1136148727353\n",
            "MAE: 12.3263177737273\n",
            "MAPE: 1.0998744079245444\n",
            "RMSE: 16.52614942667333\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "658/658 [==============================] - 47s 52ms/step - loss: 0.0050 - val_loss: 7.5691e-04\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 32s 48ms/step - loss: 4.5760e-04 - val_loss: 3.0703e-04\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 29s 43ms/step - loss: 3.8455e-04 - val_loss: 2.7990e-04\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 31s 48ms/step - loss: 3.3148e-04 - val_loss: 2.7169e-04\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 32s 48ms/step - loss: 3.1758e-04 - val_loss: 3.2429e-04\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 30s 45ms/step - loss: 3.1560e-04 - val_loss: 2.8167e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 31s 46ms/step - loss: 2.9182e-04 - val_loss: 2.2956e-04\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 33s 50ms/step - loss: 2.7567e-04 - val_loss: 3.1277e-04\n",
            "Epoch 9/100\n",
            "658/658 [==============================] - 32s 48ms/step - loss: 2.6359e-04 - val_loss: 2.0166e-04\n",
            "Epoch 10/100\n",
            "658/658 [==============================] - 29s 44ms/step - loss: 2.5984e-04 - val_loss: 2.8283e-04\n",
            "Epoch 11/100\n",
            "658/658 [==============================] - 32s 48ms/step - loss: 2.2523e-04 - val_loss: 2.0172e-04\n",
            "Epoch 12/100\n",
            "658/658 [==============================] - 32s 49ms/step - loss: 2.2251e-04 - val_loss: 1.6006e-04\n",
            "Epoch 13/100\n",
            "658/658 [==============================] - 31s 47ms/step - loss: 2.1315e-04 - val_loss: 2.1871e-04\n",
            "Epoch 14/100\n",
            "658/658 [==============================] - 29s 44ms/step - loss: 2.1465e-04 - val_loss: 2.6603e-04\n",
            "Epoch 15/100\n",
            "658/658 [==============================] - 31s 48ms/step - loss: 2.0007e-04 - val_loss: 2.5603e-04\n",
            "Epoch 16/100\n",
            "658/658 [==============================] - 31s 47ms/step - loss: 1.9821e-04 - val_loss: 2.9104e-04\n",
            "Epoch 17/100\n",
            "658/658 [==============================] - 29s 44ms/step - loss: 1.8819e-04 - val_loss: 2.5831e-04\n",
            "274/274 [==============================] - 5s 10ms/step\n",
            "Look Back: 10\n",
            "MSE: 237.1431556977455\n",
            "MAE: 11.37312148800269\n",
            "MAPE: 1.0149907967349194\n",
            "RMSE: 15.399453097358538\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "658/658 [==============================] - 51s 58ms/step - loss: 0.0057 - val_loss: 5.1732e-04\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 35s 54ms/step - loss: 4.2844e-04 - val_loss: 3.1799e-04\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 36s 55ms/step - loss: 3.8690e-04 - val_loss: 5.0534e-04\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 36s 54ms/step - loss: 3.7553e-04 - val_loss: 2.7572e-04\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 36s 54ms/step - loss: 3.5090e-04 - val_loss: 3.0265e-04\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 36s 54ms/step - loss: 2.9303e-04 - val_loss: 4.1375e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 35s 54ms/step - loss: 2.8928e-04 - val_loss: 3.2243e-04\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 35s 54ms/step - loss: 2.9124e-04 - val_loss: 3.0686e-04\n",
            "Epoch 9/100\n",
            "658/658 [==============================] - 36s 54ms/step - loss: 2.5416e-04 - val_loss: 2.4313e-04\n",
            "Epoch 10/100\n",
            "658/658 [==============================] - 35s 54ms/step - loss: 2.5213e-04 - val_loss: 3.3384e-04\n",
            "Epoch 11/100\n",
            "658/658 [==============================] - 35s 53ms/step - loss: 2.5057e-04 - val_loss: 3.5162e-04\n",
            "Epoch 12/100\n",
            "658/658 [==============================] - 34s 51ms/step - loss: 2.0897e-04 - val_loss: 1.9348e-04\n",
            "Epoch 13/100\n",
            "658/658 [==============================] - 35s 53ms/step - loss: 1.9414e-04 - val_loss: 2.1060e-04\n",
            "Epoch 14/100\n",
            "658/658 [==============================] - 34s 52ms/step - loss: 2.1871e-04 - val_loss: 2.5991e-04\n",
            "Epoch 15/100\n",
            "658/658 [==============================] - 34s 51ms/step - loss: 1.9373e-04 - val_loss: 1.5584e-04\n",
            "Epoch 16/100\n",
            "658/658 [==============================] - 35s 52ms/step - loss: 1.8866e-04 - val_loss: 1.8870e-04\n",
            "Epoch 17/100\n",
            "658/658 [==============================] - 34s 52ms/step - loss: 1.9189e-04 - val_loss: 2.3633e-04\n",
            "Epoch 18/100\n",
            "658/658 [==============================] - 34s 52ms/step - loss: 1.7618e-04 - val_loss: 1.6738e-04\n",
            "Epoch 19/100\n",
            "658/658 [==============================] - 35s 53ms/step - loss: 1.7214e-04 - val_loss: 2.4822e-04\n",
            "Epoch 20/100\n",
            "658/658 [==============================] - 35s 54ms/step - loss: 1.7415e-04 - val_loss: 1.6027e-04\n",
            "274/274 [==============================] - 7s 16ms/step\n",
            "Look Back: 12\n",
            "MSE: 215.804717357311\n",
            "MAE: 10.895586802038\n",
            "MAPE: 0.963430031093524\n",
            "RMSE: 14.69029330399196\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "658/658 [==============================] - 60s 67ms/step - loss: 0.0046 - val_loss: 0.0013\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 41s 62ms/step - loss: 4.4604e-04 - val_loss: 2.8489e-04\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 42s 64ms/step - loss: 3.6837e-04 - val_loss: 2.7800e-04\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 40s 61ms/step - loss: 3.5134e-04 - val_loss: 2.4787e-04\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 40s 61ms/step - loss: 3.1676e-04 - val_loss: 2.4309e-04\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 44s 67ms/step - loss: 3.0594e-04 - val_loss: 4.2673e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 41s 62ms/step - loss: 3.0473e-04 - val_loss: 2.3409e-04\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 40s 61ms/step - loss: 2.5659e-04 - val_loss: 2.2271e-04\n",
            "Epoch 9/100\n",
            "658/658 [==============================] - 45s 68ms/step - loss: 2.6333e-04 - val_loss: 2.0031e-04\n",
            "Epoch 10/100\n",
            "658/658 [==============================] - 40s 61ms/step - loss: 2.3450e-04 - val_loss: 2.3035e-04\n",
            "Epoch 11/100\n",
            "658/658 [==============================] - 42s 63ms/step - loss: 2.2799e-04 - val_loss: 2.7163e-04\n",
            "Epoch 12/100\n",
            "658/658 [==============================] - 43s 65ms/step - loss: 2.1898e-04 - val_loss: 1.7624e-04\n",
            "Epoch 13/100\n",
            "658/658 [==============================] - 41s 63ms/step - loss: 2.0402e-04 - val_loss: 1.9572e-04\n",
            "Epoch 14/100\n",
            "658/658 [==============================] - 41s 63ms/step - loss: 2.1220e-04 - val_loss: 1.5206e-04\n",
            "Epoch 15/100\n",
            "658/658 [==============================] - 43s 66ms/step - loss: 2.0486e-04 - val_loss: 1.5024e-04\n",
            "Epoch 16/100\n",
            "658/658 [==============================] - 41s 62ms/step - loss: 1.9508e-04 - val_loss: 1.7475e-04\n",
            "Epoch 17/100\n",
            "658/658 [==============================] - 41s 63ms/step - loss: 1.7748e-04 - val_loss: 3.2253e-04\n",
            "Epoch 18/100\n",
            "658/658 [==============================] - 43s 65ms/step - loss: 1.8403e-04 - val_loss: 1.7461e-04\n",
            "Epoch 19/100\n",
            "658/658 [==============================] - 40s 61ms/step - loss: 1.7981e-04 - val_loss: 1.4604e-04\n",
            "Epoch 20/100\n",
            "658/658 [==============================] - 40s 61ms/step - loss: 1.7553e-04 - val_loss: 1.6245e-04\n",
            "Epoch 21/100\n",
            "658/658 [==============================] - 42s 64ms/step - loss: 1.7110e-04 - val_loss: 2.3043e-04\n",
            "Epoch 22/100\n",
            "658/658 [==============================] - 41s 63ms/step - loss: 1.6910e-04 - val_loss: 1.5647e-04\n",
            "Epoch 23/100\n",
            "658/658 [==============================] - 40s 61ms/step - loss: 1.5889e-04 - val_loss: 2.4774e-04\n",
            "Epoch 24/100\n",
            "658/658 [==============================] - 41s 62ms/step - loss: 1.6826e-04 - val_loss: 1.8103e-04\n",
            "274/274 [==============================] - 7s 16ms/step\n",
            "Look Back: 14\n",
            "MSE: 221.03820112139223\n",
            "MAE: 11.24272118476628\n",
            "MAPE: 1.0012588195349266\n",
            "RMSE: 14.867353534553224\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "658/658 [==============================] - 60s 70ms/step - loss: 0.0043 - val_loss: 9.4237e-04\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 46s 69ms/step - loss: 4.5127e-04 - val_loss: 3.2185e-04\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 43s 65ms/step - loss: 3.6819e-04 - val_loss: 2.8933e-04\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 45s 68ms/step - loss: 3.4899e-04 - val_loss: 3.0518e-04\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 44s 66ms/step - loss: 3.2206e-04 - val_loss: 7.3728e-04\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 46s 70ms/step - loss: 2.8345e-04 - val_loss: 3.7096e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 43s 65ms/step - loss: 3.2069e-04 - val_loss: 2.8803e-04\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 46s 69ms/step - loss: 2.6677e-04 - val_loss: 2.0850e-04\n",
            "Epoch 9/100\n",
            "658/658 [==============================] - 44s 67ms/step - loss: 2.4410e-04 - val_loss: 3.2834e-04\n",
            "Epoch 10/100\n",
            "658/658 [==============================] - 44s 67ms/step - loss: 2.1171e-04 - val_loss: 2.2423e-04\n",
            "Epoch 11/100\n",
            "658/658 [==============================] - 45s 68ms/step - loss: 2.1559e-04 - val_loss: 1.6881e-04\n",
            "Epoch 12/100\n",
            "658/658 [==============================] - 43s 65ms/step - loss: 2.2909e-04 - val_loss: 1.9419e-04\n",
            "Epoch 13/100\n",
            "658/658 [==============================] - 46s 70ms/step - loss: 1.8114e-04 - val_loss: 2.2137e-04\n",
            "Epoch 14/100\n",
            "658/658 [==============================] - 43s 66ms/step - loss: 1.8735e-04 - val_loss: 2.2829e-04\n",
            "Epoch 15/100\n",
            "658/658 [==============================] - 46s 70ms/step - loss: 1.9831e-04 - val_loss: 1.7385e-04\n",
            "Epoch 16/100\n",
            "658/658 [==============================] - 43s 65ms/step - loss: 1.7891e-04 - val_loss: 1.9965e-04\n",
            "274/274 [==============================] - 7s 18ms/step\n",
            "Look Back: 16\n",
            "MSE: 245.0858128899103\n",
            "MAE: 11.793253402416571\n",
            "MAPE: 1.0527108875869975\n",
            "RMSE: 15.655216794727254\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "658/658 [==============================] - 64s 80ms/step - loss: 0.0042 - val_loss: 3.6124e-04\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 50s 77ms/step - loss: 4.1073e-04 - val_loss: 3.9968e-04\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 50s 77ms/step - loss: 3.7808e-04 - val_loss: 2.5354e-04\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 51s 77ms/step - loss: 3.4455e-04 - val_loss: 3.4003e-04\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 50s 76ms/step - loss: 3.0245e-04 - val_loss: 2.3155e-04\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 48s 73ms/step - loss: 2.9856e-04 - val_loss: 2.0925e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 50s 76ms/step - loss: 2.6769e-04 - val_loss: 2.5997e-04\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 50s 77ms/step - loss: 2.8089e-04 - val_loss: 2.0035e-04\n",
            "Epoch 9/100\n",
            "658/658 [==============================] - 51s 77ms/step - loss: 2.2033e-04 - val_loss: 4.1154e-04\n",
            "Epoch 10/100\n",
            "658/658 [==============================] - 48s 73ms/step - loss: 2.3880e-04 - val_loss: 2.5347e-04\n",
            "Epoch 11/100\n",
            "658/658 [==============================] - 49s 75ms/step - loss: 2.1375e-04 - val_loss: 2.6254e-04\n",
            "Epoch 12/100\n",
            "658/658 [==============================] - 50s 76ms/step - loss: 2.1159e-04 - val_loss: 2.4762e-04\n",
            "Epoch 13/100\n",
            "658/658 [==============================] - 52s 79ms/step - loss: 2.2458e-04 - val_loss: 3.6353e-04\n",
            "274/274 [==============================] - 6s 15ms/step\n",
            "Look Back: 18\n",
            "MSE: 303.44587759391896\n",
            "MAE: 12.870932955826017\n",
            "MAPE: 1.1448876617143597\n",
            "RMSE: 17.419697976541354\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "658/658 [==============================] - 80s 97ms/step - loss: 0.0043 - val_loss: 5.6288e-04\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 56s 85ms/step - loss: 4.1468e-04 - val_loss: 5.9776e-04\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 56s 85ms/step - loss: 3.9627e-04 - val_loss: 2.9640e-04\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 56s 85ms/step - loss: 3.2390e-04 - val_loss: 3.4767e-04\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 56s 85ms/step - loss: 3.1571e-04 - val_loss: 3.1859e-04\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 59s 89ms/step - loss: 3.0475e-04 - val_loss: 4.1667e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 56s 86ms/step - loss: 2.9399e-04 - val_loss: 6.6394e-04\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 56s 85ms/step - loss: 2.6692e-04 - val_loss: 4.1072e-04\n",
            "274/274 [==============================] - 6s 16ms/step\n",
            "Look Back: 20\n",
            "MSE: 441.71032306129615\n",
            "MAE: 16.216896768155657\n",
            "MAPE: 1.4837647135846943\n",
            "RMSE: 21.016905649055385\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "657/657 [==============================] - 55s 69ms/step - loss: 0.0043 - val_loss: 4.7624e-04\n",
            "Epoch 2/100\n",
            "657/657 [==============================] - 42s 63ms/step - loss: 4.2143e-04 - val_loss: 3.2782e-04\n",
            "Epoch 3/100\n",
            "657/657 [==============================] - 42s 63ms/step - loss: 3.3089e-04 - val_loss: 2.5599e-04\n",
            "Epoch 4/100\n",
            "657/657 [==============================] - 44s 67ms/step - loss: 3.6410e-04 - val_loss: 2.8651e-04\n",
            "Epoch 5/100\n",
            "657/657 [==============================] - 42s 64ms/step - loss: 2.9642e-04 - val_loss: 2.1005e-04\n",
            "Epoch 6/100\n",
            "657/657 [==============================] - 41s 62ms/step - loss: 2.8492e-04 - val_loss: 2.1239e-04\n",
            "Epoch 7/100\n",
            "657/657 [==============================] - 42s 64ms/step - loss: 2.6449e-04 - val_loss: 2.4553e-04\n",
            "Epoch 8/100\n",
            "657/657 [==============================] - 43s 65ms/step - loss: 2.5630e-04 - val_loss: 1.9002e-04\n",
            "Epoch 9/100\n",
            "657/657 [==============================] - 41s 62ms/step - loss: 2.6646e-04 - val_loss: 2.2350e-04\n",
            "Epoch 10/100\n",
            "657/657 [==============================] - 41s 62ms/step - loss: 2.1659e-04 - val_loss: 1.8445e-04\n",
            "Epoch 11/100\n",
            "657/657 [==============================] - 44s 66ms/step - loss: 2.1196e-04 - val_loss: 1.6043e-04\n",
            "Epoch 12/100\n",
            "657/657 [==============================] - 41s 62ms/step - loss: 1.9980e-04 - val_loss: 2.1664e-04\n",
            "Epoch 13/100\n",
            "657/657 [==============================] - 41s 62ms/step - loss: 1.9571e-04 - val_loss: 1.6139e-04\n",
            "Epoch 14/100\n",
            "657/657 [==============================] - 44s 67ms/step - loss: 1.9925e-04 - val_loss: 1.6426e-04\n",
            "Epoch 15/100\n",
            "657/657 [==============================] - 42s 63ms/step - loss: 1.9905e-04 - val_loss: 2.2417e-04\n",
            "Epoch 16/100\n",
            "657/657 [==============================] - 41s 62ms/step - loss: 1.8228e-04 - val_loss: 2.6826e-04\n",
            "274/274 [==============================] - 7s 17ms/step\n",
            "Look Back: 22\n",
            "MSE: 244.3436445411139\n",
            "MAE: 11.646854687694509\n",
            "MAPE: 1.0416668720289628\n",
            "RMSE: 15.631495275280413\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "657/657 [==============================] - 80s 102ms/step - loss: 0.0049 - val_loss: 0.0011\n",
            "Epoch 2/100\n",
            "657/657 [==============================] - 61s 94ms/step - loss: 4.5282e-04 - val_loss: 3.1814e-04\n",
            "Epoch 3/100\n",
            "657/657 [==============================] - 64s 97ms/step - loss: 3.5518e-04 - val_loss: 2.7971e-04\n",
            "Epoch 4/100\n",
            "657/657 [==============================] - 61s 93ms/step - loss: 3.2301e-04 - val_loss: 2.5985e-04\n",
            "Epoch 5/100\n",
            "657/657 [==============================] - 63s 96ms/step - loss: 3.1305e-04 - val_loss: 2.4598e-04\n",
            "Epoch 6/100\n",
            "657/657 [==============================] - 62s 95ms/step - loss: 2.9177e-04 - val_loss: 2.2821e-04\n",
            "Epoch 7/100\n",
            "657/657 [==============================] - 64s 98ms/step - loss: 2.7356e-04 - val_loss: 2.3164e-04\n",
            "Epoch 8/100\n",
            "657/657 [==============================] - 61s 93ms/step - loss: 2.7351e-04 - val_loss: 2.1411e-04\n",
            "Epoch 9/100\n",
            "657/657 [==============================] - 64s 97ms/step - loss: 2.4394e-04 - val_loss: 2.9404e-04\n",
            "Epoch 10/100\n",
            "657/657 [==============================] - 63s 95ms/step - loss: 2.3788e-04 - val_loss: 2.4733e-04\n",
            "Epoch 11/100\n",
            "657/657 [==============================] - 65s 99ms/step - loss: 2.3575e-04 - val_loss: 2.4242e-04\n",
            "Epoch 12/100\n",
            "657/657 [==============================] - 62s 94ms/step - loss: 2.2065e-04 - val_loss: 2.1409e-04\n",
            "Epoch 13/100\n",
            "657/657 [==============================] - 66s 100ms/step - loss: 2.0722e-04 - val_loss: 1.8505e-04\n",
            "Epoch 14/100\n",
            "657/657 [==============================] - 62s 95ms/step - loss: 2.0028e-04 - val_loss: 2.1691e-04\n",
            "Epoch 15/100\n",
            "657/657 [==============================] - 65s 99ms/step - loss: 1.8485e-04 - val_loss: 1.8149e-04\n",
            "Epoch 16/100\n",
            "657/657 [==============================] - 62s 94ms/step - loss: 1.8652e-04 - val_loss: 1.8398e-04\n",
            "Epoch 17/100\n",
            "657/657 [==============================] - 65s 99ms/step - loss: 1.7558e-04 - val_loss: 1.7412e-04\n",
            "Epoch 18/100\n",
            "657/657 [==============================] - 64s 98ms/step - loss: 1.7016e-04 - val_loss: 2.5069e-04\n",
            "Epoch 19/100\n",
            "657/657 [==============================] - 63s 96ms/step - loss: 1.7339e-04 - val_loss: 1.5210e-04\n",
            "Epoch 20/100\n",
            "657/657 [==============================] - 64s 97ms/step - loss: 1.6372e-04 - val_loss: 1.8578e-04\n",
            "Epoch 21/100\n",
            "657/657 [==============================] - 63s 96ms/step - loss: 1.6403e-04 - val_loss: 1.4466e-04\n",
            "Epoch 22/100\n",
            "657/657 [==============================] - 65s 98ms/step - loss: 1.5772e-04 - val_loss: 2.4069e-04\n",
            "Epoch 23/100\n",
            "657/657 [==============================] - 62s 94ms/step - loss: 1.4751e-04 - val_loss: 1.5906e-04\n",
            "Epoch 24/100\n",
            "657/657 [==============================] - 64s 98ms/step - loss: 1.5185e-04 - val_loss: 1.4002e-04\n",
            "Epoch 25/100\n",
            "657/657 [==============================] - 64s 98ms/step - loss: 1.4912e-04 - val_loss: 1.7050e-04\n",
            "Epoch 26/100\n",
            "657/657 [==============================] - 65s 99ms/step - loss: 1.3825e-04 - val_loss: 1.2235e-04\n",
            "Epoch 27/100\n",
            "657/657 [==============================] - 62s 94ms/step - loss: 1.3875e-04 - val_loss: 1.2939e-04\n",
            "Epoch 28/100\n",
            "657/657 [==============================] - 65s 98ms/step - loss: 1.3639e-04 - val_loss: 1.4962e-04\n",
            "Epoch 29/100\n",
            "657/657 [==============================] - 61s 94ms/step - loss: 1.3381e-04 - val_loss: 1.2866e-04\n",
            "Epoch 30/100\n",
            "657/657 [==============================] - 65s 99ms/step - loss: 1.3184e-04 - val_loss: 2.2232e-04\n",
            "Epoch 31/100\n",
            "657/657 [==============================] - 61s 93ms/step - loss: 1.2919e-04 - val_loss: 1.4894e-04\n",
            "274/274 [==============================] - 10s 25ms/step\n",
            "Look Back: 24\n",
            "MSE: 171.58644578995913\n",
            "MAE: 9.643722099752113\n",
            "MAPE: 0.855615884925469\n",
            "RMSE: 13.099100953499027\n",
            "--------------------\n"
          ]
        }
      ]
    }
  ]
}