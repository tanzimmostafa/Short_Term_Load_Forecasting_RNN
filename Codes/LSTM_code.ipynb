{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Initial Part Constant For All Models"
      ],
      "metadata": {
        "id": "ADJcydj9-8E3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHJ6DRcUq4j6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBuos30wsaHV",
        "outputId": "0eb839ea-3641-472e-b3ad-7115479c9a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to your CSV file\n",
        "csv_file_path = '/content/drive/MyDrive/IS_STLF_Dataset_2012_2015/ERCOT_2012_to_2015.csv'"
      ],
      "metadata": {
        "id": "5Vk_QflXt_Md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2: Finding best hyperparameters/ architecture"
      ],
      "metadata": {
        "id": "O9NtlfL199MH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset into a DataFrame\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "nYIXw8lE9-eL",
        "outputId": "efd812e5-55e9-4dd9-d0d5-d9d99f5e98a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Date  Day of Week(0-6)  Day of the Month(1-31)  \\\n",
              "0  1/1/2012                 6                       1   \n",
              "1  1/1/2012                 6                       1   \n",
              "2  1/1/2012                 6                       1   \n",
              "3  1/1/2012                 6                       1   \n",
              "4  1/1/2012                 6                       1   \n",
              "\n",
              "   Month of the Year(1-12)  Time of Day(0-23)  Holidays  Humidity  \\\n",
              "0                        1                  1         1     34.89   \n",
              "1                        1                  2         1     37.89   \n",
              "2                        1                  3         1     46.46   \n",
              "3                        1                  4         1     54.48   \n",
              "4                        1                  5         1     63.22   \n",
              "\n",
              "   Temperature   Load WEST  \n",
              "0         13.2  849.000892  \n",
              "1         12.0  845.097364  \n",
              "2         10.2  840.902849  \n",
              "3          8.4  845.452257  \n",
              "4          6.6  862.369386  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78d8dbfc-a667-4c29-afd3-556c3c5eb0d8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Day of Week(0-6)</th>\n",
              "      <th>Day of the Month(1-31)</th>\n",
              "      <th>Month of the Year(1-12)</th>\n",
              "      <th>Time of Day(0-23)</th>\n",
              "      <th>Holidays</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Load WEST</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/1/2012</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34.89</td>\n",
              "      <td>13.2</td>\n",
              "      <td>849.000892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/1/2012</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>37.89</td>\n",
              "      <td>12.0</td>\n",
              "      <td>845.097364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/1/2012</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>46.46</td>\n",
              "      <td>10.2</td>\n",
              "      <td>840.902849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/1/2012</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>54.48</td>\n",
              "      <td>8.4</td>\n",
              "      <td>845.452257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/1/2012</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>63.22</td>\n",
              "      <td>6.6</td>\n",
              "      <td>862.369386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78d8dbfc-a667-4c29-afd3-556c3c5eb0d8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-78d8dbfc-a667-4c29-afd3-556c3c5eb0d8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-78d8dbfc-a667-4c29-afd3-556c3c5eb0d8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-84918b24-b495-42b7-a957-16b5bf0cf17f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-84918b24-b495-42b7-a957-16b5bf0cf17f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-84918b24-b495-42b7-a957-16b5bf0cf17f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features and target variable\n",
        "features = ['Day of Week(0-6)', 'Day of the Month(1-31)', 'Month of the Year(1-12)', 'Time of Day(0-23)', 'Holidays', 'Humidity', 'Temperature']\n",
        "target_variable = 'Load WEST'\n",
        "data = df[['Day of Week(0-6)', 'Day of the Month(1-31)', 'Month of the Year(1-12)', 'Time of Day(0-23)', 'Holidays', 'Humidity', 'Temperature', 'Load WEST']]"
      ],
      "metadata": {
        "id": "dxrylMNT-Icl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize data using Min-Max normalization\n",
        "scaler = MinMaxScaler()\n",
        "data_normalized = scaler.fit_transform(data)"
      ],
      "metadata": {
        "id": "z9NQ1PHE-K-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(data_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10iodNh2-Nzp",
        "outputId": "4f3c2086-7e39-4233-8527-b263d469dd98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_normalized.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93054757-de04-4beb-f0d3-e37c03643cc5",
        "id": "fw9BN_TN-fnh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35064, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2015 starts fromrow 26304\n",
        "#checking\n",
        "data.iloc[26303]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dd13d96-ae74-4df2-fea0-6ac732f6184f",
        "id": "bwItuCOJ-fni"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Day of Week(0-6)              3.00000\n",
              "Day of the Month(1-31)        1.00000\n",
              "Month of the Year(1-12)       1.00000\n",
              "Time of Day(0-23)             0.00000\n",
              "Holidays                      1.00000\n",
              "Humidity                     77.15000\n",
              "Temperature                   1.20000\n",
              "Load WEST                  1504.43762\n",
              "Name: 26303, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_normalized[26303]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21c66aff-aa0c-4756-e9d9-540cade71908",
        "id": "IVJkZAnc-fni"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5       , 0.        , 0.        , 0.        , 1.        ,\n",
              "       0.75412989, 0.20517928, 0.69694446])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set=data_normalized[:26303]\n",
        "test_set=data_normalized[26303:]"
      ],
      "metadata": {
        "id": "D6n5paBT-fni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_set.shape)\n",
        "print(test_set.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c52c8488-ec85-4273-f5aa-10361011b943",
        "id": "i3E9UN8B-fni"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26303, 8)\n",
            "(8761, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to prepare sequences for LSTM\n",
        "def prepare_sequences(data, look_back):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - look_back):\n",
        "        X.append(data[i:(i + look_back), :])\n",
        "        y.append(data[i + look_back, -1])  # Assuming Load WEST is the last column\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Set the look-back window\n",
        "look_back = 12 # Adjust this value based on your analysis #14 turned out to be best"
      ],
      "metadata": {
        "id": "wdYfAwjK-tP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare sequences for train set\n",
        "X_train_I, y_train_I = prepare_sequences(train_set, look_back)"
      ],
      "metadata": {
        "id": "cXIQpqxj-0OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare sequences for test set\n",
        "X_test, y_test = prepare_sequences(test_set, look_back)"
      ],
      "metadata": {
        "id": "0TlX-4ok-0OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_I.shape)\n",
        "print(y_train_I.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0e88265-6a56-4bbc-cea5-6fc2339d693d",
        "id": "95jqsT8L-0OS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26291, 12, 8)\n",
            "(26291,)\n",
            "(8749, 12, 8)\n",
            "(8749,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training, validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_I, y_train_I, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "T2HiUgjl-0OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45b0ff67-e9a9-43b7-e05d-609223ca0a32",
        "id": "sTXkkW1X-0OT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21032, 12, 8)\n",
            "(21032,)\n",
            "(5259, 12, 8)\n",
            "(5259,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c734ae67-8e7c-449a-ec1e-3070da0b3b1e",
        "id": "ZE0tkMUp-0OT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRXQ4Gtn_khd",
        "outputId": "4292913b-b2c0-4ef5-a743-7a0134ed6e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.14.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.11.17)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.6 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Assuming you have X_train, y_train, X_val, y_val defined\n",
        "\n",
        "# Function to build the model\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Tune the number of LSTM units\n",
        "    model.add(LSTM(units=hp.Int('units', min_value=30, max_value=80, step=10),\n",
        "                   return_sequences=True,\n",
        "                   input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "\n",
        "    # Tune the number of intermediate LSTM layers\n",
        "    for _ in range(hp.Int('num_layers', min_value=1, max_value=5)):\n",
        "        model.add(LSTM(units=hp.Int('units', min_value=30, max_value=80, step=10), return_sequences=True))\n",
        "\n",
        "    # Manually set return_sequences=False for the last LSTM layer\n",
        "    model.add(LSTM(units=hp.Int('units_last', min_value=30, max_value=80, step=10), return_sequences=False))\n",
        "\n",
        "    # Dense layer for final prediction\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    # Choose between Adam and Nadam optimizers\n",
        "    optimizer_choice = hp.Choice('optimizer', ['adam', 'nadam'])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=optimizer_choice, loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define the tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=10,  # Adjust as needed\n",
        "    executions_per_trial=1,\n",
        "    directory='my_tuner_directory',\n",
        "    project_name='lstm_tuning'\n",
        ")\n",
        "\n",
        "# Early stopping to stop training when the validation loss doesn't improve\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Perform the search\n",
        "tuner.search(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Build the final model with the best hyperparameters\n",
        "final_model = build_model(best_hps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmb-wdi9DBQS",
        "outputId": "f17d87f6-1ca7-46ff-e581-10783d579eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 08m 13s]\n",
            "val_loss: 0.00014028121950104833\n",
            "\n",
            "Best val_loss So Far: 0.00010825267963809893\n",
            "Total elapsed time: 01h 28m 37s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a903438-g6Mu",
        "outputId": "898c905a-aa84-49ae-890b-f04565072584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters at 0x7d58812f3f40>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(f\"Number of Units: {best_hps.get('units')}\")\n",
        "print(f\"Number of Intermediate Layers: {best_hps.get('num_layers')}\")\n",
        "print(f\"Number of Units in Last Layer: {best_hps.get('units_last')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YJHaEux8Ygc",
        "outputId": "1685bf0b-bb6b-4aad-ee78-9923d1bd9990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters:\n",
            "Number of Units: 40\n",
            "Number of Intermediate Layers: 2\n",
            "Number of Units in Last Layer: 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(best_hps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UktZiwLJl1g8",
        "outputId": "9eedc94e-0f41-4dfa-b7d2-af5b14d53c58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume you have obtained best_hps as mentioned before\n",
        "\n",
        "# Print all attributes and their values\n",
        "for key, value in best_hps.__dict__.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cLPhcv8lygW",
        "outputId": "17285c64-513e-4949-8c8e-6d4ac3f852df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_name_scopes: []\n",
            "_conditions: []\n",
            "_hps: defaultdict(<class 'list'>, {'units': [Int(name: 'units', min_value: 30, max_value: 80, step: 10, sampling: linear, default: 30)], 'num_layers': [Int(name: 'num_layers', min_value: 1, max_value: 5, step: 1, sampling: linear, default: 1)], 'units_last': [Int(name: 'units_last', min_value: 30, max_value: 80, step: 10, sampling: linear, default: 30)], 'optimizer': [Choice(name: 'optimizer', values: ['adam', 'nadam'], ordered: False, default: adam)]})\n",
            "_space: [Int(name: 'units', min_value: 30, max_value: 80, step: 10, sampling: linear, default: 30), Int(name: 'num_layers', min_value: 1, max_value: 5, step: 1, sampling: linear, default: 1), Int(name: 'units_last', min_value: 30, max_value: 80, step: 10, sampling: linear, default: 30), Choice(name: 'optimizer', values: ['adam', 'nadam'], ordered: False, default: adam)]\n",
            "values: {'units': 40, 'num_layers': 2, 'units_last': 80, 'optimizer': 'nadam'}\n",
            "active_scopes: []\n",
            "inactive_scopes: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the final model\n",
        "history = final_model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_loss = final_model.evaluate(X_test, y_test)\n",
        "\n",
        "# You can access the best model using the 'best_model' variable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r15IYEtQxLVI",
        "outputId": "06b41c7a-71b2-408d-ee65-90b55e3f852f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "658/658 [==============================] - 34s 36ms/step - loss: 0.0088 - val_loss: 0.0027\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 24s 36ms/step - loss: 0.0016 - val_loss: 8.8388e-04\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 22s 33ms/step - loss: 7.6310e-04 - val_loss: 0.0017\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 23s 35ms/step - loss: 4.7016e-04 - val_loss: 3.0672e-04\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 24s 37ms/step - loss: 3.0676e-04 - val_loss: 2.2553e-04\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 21s 33ms/step - loss: 2.6332e-04 - val_loss: 5.1869e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 2.4859e-04 - val_loss: 2.9260e-04\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 22s 33ms/step - loss: 2.2422e-04 - val_loss: 3.0151e-04\n",
            "Epoch 9/100\n",
            "658/658 [==============================] - 23s 34ms/step - loss: 2.0602e-04 - val_loss: 2.4478e-04\n",
            "Epoch 10/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 2.0402e-04 - val_loss: 2.0396e-04\n",
            "Epoch 11/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 1.8509e-04 - val_loss: 1.8293e-04\n",
            "Epoch 12/100\n",
            "658/658 [==============================] - 23s 36ms/step - loss: 1.7221e-04 - val_loss: 2.0111e-04\n",
            "Epoch 13/100\n",
            "658/658 [==============================] - 22s 33ms/step - loss: 1.6866e-04 - val_loss: 2.2569e-04\n",
            "Epoch 14/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 1.6108e-04 - val_loss: 1.6253e-04\n",
            "Epoch 15/100\n",
            "658/658 [==============================] - 22s 33ms/step - loss: 1.5776e-04 - val_loss: 1.5710e-04\n",
            "Epoch 16/100\n",
            "658/658 [==============================] - 26s 39ms/step - loss: 1.5459e-04 - val_loss: 2.0499e-04\n",
            "Epoch 17/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 1.4901e-04 - val_loss: 1.4170e-04\n",
            "Epoch 18/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 1.4106e-04 - val_loss: 1.3034e-04\n",
            "Epoch 19/100\n",
            "658/658 [==============================] - 23s 34ms/step - loss: 1.3945e-04 - val_loss: 1.8806e-04\n",
            "Epoch 20/100\n",
            "658/658 [==============================] - 22s 34ms/step - loss: 1.3772e-04 - val_loss: 1.3769e-04\n",
            "Epoch 21/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 1.3142e-04 - val_loss: 2.5188e-04\n",
            "Epoch 22/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 1.2787e-04 - val_loss: 8.8039e-04\n",
            "Epoch 23/100\n",
            "658/658 [==============================] - 23s 35ms/step - loss: 1.2815e-04 - val_loss: 1.2741e-04\n",
            "Epoch 24/100\n",
            "658/658 [==============================] - 22s 33ms/step - loss: 1.2250e-04 - val_loss: 2.3243e-04\n",
            "Epoch 25/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 1.1970e-04 - val_loss: 1.4806e-04\n",
            "Epoch 26/100\n",
            "658/658 [==============================] - 22s 33ms/step - loss: 1.1959e-04 - val_loss: 1.1301e-04\n",
            "Epoch 27/100\n",
            "658/658 [==============================] - 25s 39ms/step - loss: 1.1464e-04 - val_loss: 1.6786e-04\n",
            "Epoch 28/100\n",
            "658/658 [==============================] - 22s 33ms/step - loss: 1.1226e-04 - val_loss: 1.3214e-04\n",
            "Epoch 29/100\n",
            "658/658 [==============================] - 22s 33ms/step - loss: 1.1383e-04 - val_loss: 1.1288e-04\n",
            "Epoch 30/100\n",
            "658/658 [==============================] - 23s 35ms/step - loss: 1.1242e-04 - val_loss: 1.2518e-04\n",
            "Epoch 31/100\n",
            "658/658 [==============================] - 21s 33ms/step - loss: 1.0850e-04 - val_loss: 1.0889e-04\n",
            "Epoch 32/100\n",
            "658/658 [==============================] - 23s 35ms/step - loss: 1.0739e-04 - val_loss: 1.4367e-04\n",
            "Epoch 33/100\n",
            "658/658 [==============================] - 25s 38ms/step - loss: 1.0588e-04 - val_loss: 1.1931e-04\n",
            "Epoch 34/100\n",
            "658/658 [==============================] - 23s 35ms/step - loss: 1.0513e-04 - val_loss: 2.3740e-04\n",
            "Epoch 35/100\n",
            "658/658 [==============================] - 23s 34ms/step - loss: 1.0395e-04 - val_loss: 1.1152e-04\n",
            "Epoch 36/100\n",
            "658/658 [==============================] - 23s 35ms/step - loss: 1.0315e-04 - val_loss: 2.2025e-04\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 9.7043e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fE0a2yxmcOk",
        "outputId": "62e2c82e-9efe-4980-d4be-7ac9fe0703ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.704315743874758e-05"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXtBcDT2jFlk",
        "outputId": "fbca8460-f13b-4a16-e925-23117f9a3e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8749, 12, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[:, -1, :].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHY4f0BriVa9",
        "outputId": "b23b3a6f-f507-42ab-fec2-76e5d8d84aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8749, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "predictions = final_model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g8TY6-MtXDh",
        "outputId": "190c3fc7-2ed4-4ced-fb2e-f2dd775e8d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "274/274 [==============================] - 4s 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN1UfC79tfbE",
        "outputId": "158a51fa-dd1b-4e3f-8104-a110b5c73123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8749, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Drqf-P4ht4lU",
        "outputId": "d492ac38-6052-4f70-aedd-cb5ab7e0dd77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8749,)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Invert the predictions and actual values to compare with the original scale\n",
        "predictions_original = scaler.inverse_transform(np.concatenate((X_test[:, -1, :-1], predictions), axis=1))[:, -1]\n",
        "y_test_original = scaler.inverse_transform(np.concatenate((X_test[:, -1, :-1], y_test.reshape(-1, 1)), axis=1))[:, -1]\n"
      ],
      "metadata": {
        "id": "dd1jV5HDtOej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
        "mape = mean_absolute_percentage_error(y_test_original, predictions_original)\n",
        "r2 = r2_score(y_test_original, predictions_original)\n",
        "\n",
        "print(f'Mean Absolute Percentage Error (MAPE): {mape * 100:.2f}%')\n",
        "print(f'R-squared (R2): {r2:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A0JjK3QgrPl",
        "outputId": "82e7d82f-a20e-45b4-f5f1-63a711f87894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Percentage Error (MAPE): 0.83%\n",
            "R-squared (R2): 0.9972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "mae = mean_absolute_error(y_test_original, predictions_original)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_original, predictions_original))\n",
        "\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL_tsTAckhKY",
        "outputId": "0b3c9f72-7491-43cb-ce68-b4ad3d1098da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 9.066112954820625\n",
            "Root Mean Squared Error (RMSE): 12.33435306942593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test_original, predictions_original)\n",
        "print(\"Mean Squared Error (MSE):\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY3QeXPvkkZy",
        "outputId": "be9a5dec-f044-4fd6-c564-dd95f583c304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 152.13626564125684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RguQki_2FaKD",
        "outputId": "0913243e-6863-47b2-864e-0640f39157ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 12, 40)            7840      \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 12, 40)            12960     \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 12, 40)            12960     \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 80)                38720     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 81        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 72561 (283.44 KB)\n",
            "Trainable params: 72561 (283.44 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, layer in enumerate(final_model.layers):\n",
        "    print(f\"Layer {i+1}: {layer.name} - Type: {type(layer).__name__}\")\n",
        "    if hasattr(layer, 'units'):\n",
        "        print(f\"Number of Neurons: {layer.units}\")\n",
        "    print(\"-----------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLCpS7iVFmbG",
        "outputId": "72a5580e-9687-445c-fcaa-59d540dde03c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1: lstm_4 - Type: LSTM\n",
            "Number of Neurons: 40\n",
            "-----------------------------------\n",
            "Layer 2: lstm_5 - Type: LSTM\n",
            "Number of Neurons: 40\n",
            "-----------------------------------\n",
            "Layer 3: lstm_6 - Type: LSTM\n",
            "Number of Neurons: 40\n",
            "-----------------------------------\n",
            "Layer 4: lstm_7 - Type: LSTM\n",
            "Number of Neurons: 80\n",
            "-----------------------------------\n",
            "Layer 5: dense_1 - Type: Dense\n",
            "Number of Neurons: 1\n",
            "-----------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 3: Using Best Hyperparameters to obtain optimum look-back window"
      ],
      "metadata": {
        "id": "Cm5Y6ufo_JU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset into a DataFrame\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "6de41ad9-ab07-4da9-fa03-3d8d49ddda3e",
        "id": "Fg2_uxYuLQ25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Date  Day of Week(0-6)  Day of the Month(1-31)  \\\n",
              "0  1/1/2012                 6                       1   \n",
              "1  1/1/2012                 6                       1   \n",
              "2  1/1/2012                 6                       1   \n",
              "3  1/1/2012                 6                       1   \n",
              "4  1/1/2012                 6                       1   \n",
              "\n",
              "   Month of the Year(1-12)  Time of Day(0-23)  Holidays  Humidity  \\\n",
              "0                        1                  1         1     34.89   \n",
              "1                        1                  2         1     37.89   \n",
              "2                        1                  3         1     46.46   \n",
              "3                        1                  4         1     54.48   \n",
              "4                        1                  5         1     63.22   \n",
              "\n",
              "   Temperature   Load WEST  \n",
              "0         13.2  849.000892  \n",
              "1         12.0  845.097364  \n",
              "2         10.2  840.902849  \n",
              "3          8.4  845.452257  \n",
              "4          6.6  862.369386  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b093d05-ee26-4c96-ac7d-33b0649dc0d5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Day of Week(0-6)</th>\n",
              "      <th>Day of the Month(1-31)</th>\n",
              "      <th>Month of the Year(1-12)</th>\n",
              "      <th>Time of Day(0-23)</th>\n",
              "      <th>Holidays</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Load WEST</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/1/2012</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34.89</td>\n",
              "      <td>13.2</td>\n",
              "      <td>849.000892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/1/2012</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>37.89</td>\n",
              "      <td>12.0</td>\n",
              "      <td>845.097364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/1/2012</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>46.46</td>\n",
              "      <td>10.2</td>\n",
              "      <td>840.902849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/1/2012</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>54.48</td>\n",
              "      <td>8.4</td>\n",
              "      <td>845.452257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/1/2012</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>63.22</td>\n",
              "      <td>6.6</td>\n",
              "      <td>862.369386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b093d05-ee26-4c96-ac7d-33b0649dc0d5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6b093d05-ee26-4c96-ac7d-33b0649dc0d5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6b093d05-ee26-4c96-ac7d-33b0649dc0d5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a8172ebb-730f-42b9-a91c-fe7355538c16\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a8172ebb-730f-42b9-a91c-fe7355538c16')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a8172ebb-730f-42b9-a91c-fe7355538c16 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features and target variable\n",
        "features = ['Day of Week(0-6)', 'Day of the Month(1-31)', 'Month of the Year(1-12)', 'Time of Day(0-23)', 'Holidays', 'Humidity', 'Temperature']\n",
        "target_variable = 'Load WEST'\n",
        "data = df[['Day of Week(0-6)', 'Day of the Month(1-31)', 'Month of the Year(1-12)', 'Time of Day(0-23)', 'Holidays', 'Humidity', 'Temperature', 'Load WEST']]"
      ],
      "metadata": {
        "id": "RaIeEONJLQ3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize data using Min-Max normalization\n",
        "scaler = MinMaxScaler()\n",
        "data_normalized = scaler.fit_transform(data)"
      ],
      "metadata": {
        "id": "LGt7rTZaLQ3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(data_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "155b18c6-b614-4193-fd6e-fc3699319392",
        "id": "XD-Gd__pLQ3M"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_normalized.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f916c3e2-c52d-4f69-b6b9-6f8c7fa3a9e1",
        "id": "ZXHKmZy-LQ3M"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35064, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2015 starts from row 26304\n",
        "#checking\n",
        "data.iloc[26303]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "052d97d3-5208-4071-b031-6822ea32f061",
        "id": "hfyoqRqfLQ3N"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Day of Week(0-6)              3.00000\n",
              "Day of the Month(1-31)        1.00000\n",
              "Month of the Year(1-12)       1.00000\n",
              "Time of Day(0-23)             0.00000\n",
              "Holidays                      1.00000\n",
              "Humidity                     77.15000\n",
              "Temperature                   1.20000\n",
              "Load WEST                  1504.43762\n",
              "Name: 26303, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_normalized[26303]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23b096d7-34d6-4240-81d9-91df07e069f6",
        "id": "lwyrrD3pLQ3N"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5       , 0.        , 0.        , 0.        , 1.        ,\n",
              "       0.75412989, 0.20517928, 0.69694446])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set=data_normalized[:26303]\n",
        "test_set=data_normalized[26303:]"
      ],
      "metadata": {
        "id": "EF_MZhXvLQ3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_set.shape)\n",
        "print(test_set.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72d251ef-ca33-4d81-f5e0-ebe91e1f8666",
        "id": "LA_cqRQ5LQ3O"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26303, 8)\n",
            "(8761, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to prepare sequences for LSTM\n",
        "def prepare_sequences(data, look_back):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - look_back):\n",
        "        X.append(data[i:(i + look_back), :])\n",
        "        y.append(data[i + look_back, -1])  # Assuming Load WEST is the last column\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Set the look-back window\n",
        "# look_back = 12 # Adjust this value based on your analysis"
      ],
      "metadata": {
        "id": "PFLKN4T6AhEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cce7aa41-c3df-43ae-fb0f-1d700756bf53",
        "id": "abkX7ZG7JQ-b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.14.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.11.17)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.6 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best LSTM Model Architecture found after hyperparameter tuning\n",
        "'''from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add LSTM layers\n",
        "model.add(LSTM(units=40, return_sequences=True, input_shape=(12, features_count)))\n",
        "model.add(LSTM(units=40, return_sequences=True))\n",
        "model.add(LSTM(units=40, return_sequences=True))\n",
        "model.add(LSTM(units=80))\n",
        "\n",
        "# Add Dense layer for final prediction\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "'''"
      ],
      "metadata": {
        "id": "YFPw5TZ8CGId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best LSTM Model Architecture\n",
        "'''\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Function to build the model with specific hyperparameters\n",
        "def build_model_with_params(units, num_layers, units_last, input_shape):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add the first LSTM layer\n",
        "    model.add(LSTM(units=units, return_sequences=True, input_shape=input_shape))\n",
        "\n",
        "    # Add intermediate LSTM layers\n",
        "    for _ in range(num_layers):\n",
        "        model.add(LSTM(units=units, return_sequences=True))\n",
        "\n",
        "    # Add the last LSTM layer with return_sequences=False\n",
        "    model.add(LSTM(units=units_last, return_sequences=False))\n",
        "\n",
        "    # Add a Dense layer for final prediction\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='nadam', loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Best Hyperparameters obtained from tuning\n",
        "best_units = 40\n",
        "best_num_layers = 2\n",
        "best_units_last = 80\n",
        "\n",
        "# Input shape based on your data\n",
        "input_shape = (12, 8)  # Update features_count based on your data\n",
        "\n",
        "# Build the model with best hyperparameters\n",
        "best_model = build_model_with_params(units=best_units, num_layers=best_num_layers, units_last=best_units_last, input_shape=input_shape)\n",
        "\n",
        "# Print model summary\n",
        "best_model.summary()\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp5ys9D_CVj2",
        "outputId": "417f01d4-39e0-42a0-de0d-ca7cabe55ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 12, 40)            7840      \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 12, 40)            12960     \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 12, 40)            12960     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 80)                38720     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 81        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 72561 (283.44 KB)\n",
            "Trainable params: 72561 (283.44 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "# Function to build the model with specific hyperparameters\n",
        "def build_model_with_params(units, num_layers, units_last, input_shape):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add the first LSTM layer\n",
        "    model.add(LSTM(units=units, return_sequences=True, input_shape=input_shape))\n",
        "\n",
        "    # Add intermediate LSTM layers\n",
        "    for _ in range(num_layers):\n",
        "        model.add(LSTM(units=units, return_sequences=True))\n",
        "\n",
        "    # Add the last LSTM layer with return_sequences=False\n",
        "    model.add(LSTM(units=units_last, return_sequences=False))\n",
        "\n",
        "    # Add a Dense layer for final prediction\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='nadam', loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Best Hyperparameters obtained from tuning\n",
        "best_units = 40\n",
        "best_num_layers = 2\n",
        "best_units_last = 80\n",
        "\n",
        "# Input shape based on your data\n",
        "# input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "\n",
        "# Automate for different look-back windows\n",
        "look_back_values = [2, 4 ,6, 8 ,10 ,12 ,14 ,16 ,18 ,20 , 22, 24]\n",
        "\n",
        "for look_back in look_back_values:\n",
        "    #X, y = prepare_sequences(data_normalized, look_back)\n",
        "\n",
        "    # Split the data into training, validation, and testing sets\n",
        "    #X_train_current, X_temp, y_train_current, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "    #X_val_current, X_test, y_val_current, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "    # Prepare sequences for train set\n",
        "    X_train_I, y_train_I = prepare_sequences(train_set, look_back)\n",
        "    # Prepare sequences for test set\n",
        "    X_test, y_test = prepare_sequences(test_set, look_back)\n",
        "\n",
        "    # Split the data into training, validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_I, y_train_I, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Build the model with specific hyperparameters\n",
        "    current_model = build_model_with_params(units=best_units, num_layers=best_num_layers, units_last=best_units_last, input_shape=(X_train.shape[1], X_train.shape[2]))\n",
        "\n",
        "    # Prepare sequences with the current look_back\n",
        "   # X_train_current, y_train_current = prepare_sequences(X_train, look_back)\n",
        "   # X_val_current, y_val_current = prepare_sequences(X_val, look_back)\n",
        "\n",
        "    # Train the model with EarlyStopping callback\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    current_model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_test_pred = current_model.predict(X_test)\n",
        "\n",
        "    # Invert the predictions and actual values to compare with the original scale\n",
        "    predictions_original = scaler.inverse_transform(np.concatenate((X_test[:, -1, :-1], y_test_pred.reshape(-1, 1)), axis=1))[:, -1]\n",
        "    y_test_original = scaler.inverse_transform(np.concatenate((X_test[:, -1, :-1], y_test.reshape(-1, 1)), axis=1))[:, -1]\n",
        "\n",
        "    # Calculate and print metrics\n",
        "    mse = mean_squared_error(y_test_original, predictions_original)\n",
        "    mae = mean_absolute_error(y_test_original, predictions_original)\n",
        "    mape = mean_absolute_percentage_error(y_test_original, predictions_original)*100\n",
        "    rmse = np.sqrt(mse)\n",
        "    #r2 = r2_score(y_test_original, predictions_original)\n",
        "\n",
        "    print(f\"Look Back: {look_back}\")\n",
        "    print(f\"MSE: {mse}\")\n",
        "    print(f\"MAE: {mae}\")\n",
        "    print(f\"MAPE: {mape}\")\n",
        "    print(f\"RMSE: {rmse}\")\n",
        "    #print(f\"R2: {r2}\")\n",
        "    print(\"--------------------\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Gn9oydIdBljv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbedc47d-b922-40e7-a354-2dc5f15b2c53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "658/658 [==============================] - 33s 19ms/step - loss: 0.0097 - val_loss: 0.0029\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 7s 11ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 10s 15ms/step - loss: 5.9025e-04 - val_loss: 5.9580e-04\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 7s 11ms/step - loss: 4.0489e-04 - val_loss: 3.7866e-04\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 10s 14ms/step - loss: 3.6192e-04 - val_loss: 3.3711e-04\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 7s 11ms/step - loss: 3.5040e-04 - val_loss: 3.1414e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 10s 15ms/step - loss: 3.4579e-04 - val_loss: 3.1322e-04\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 7s 11ms/step - loss: 3.3346e-04 - val_loss: 3.3253e-04\n",
            "Epoch 9/100\n",
            "658/658 [==============================] - 9s 14ms/step - loss: 3.3299e-04 - val_loss: 3.7841e-04\n",
            "Epoch 10/100\n",
            "658/658 [==============================] - 8s 12ms/step - loss: 3.2619e-04 - val_loss: 3.0344e-04\n",
            "Epoch 11/100\n",
            "658/658 [==============================] - 10s 15ms/step - loss: 3.2180e-04 - val_loss: 4.0800e-04\n",
            "Epoch 12/100\n",
            "658/658 [==============================] - 8s 11ms/step - loss: 3.2170e-04 - val_loss: 3.4929e-04\n",
            "Epoch 13/100\n",
            "658/658 [==============================] - 9s 14ms/step - loss: 3.1667e-04 - val_loss: 3.4461e-04\n",
            "Epoch 14/100\n",
            "658/658 [==============================] - 8s 12ms/step - loss: 3.1469e-04 - val_loss: 5.0591e-04\n",
            "Epoch 15/100\n",
            "658/658 [==============================] - 8s 13ms/step - loss: 3.1217e-04 - val_loss: 3.2227e-04\n",
            "274/274 [==============================] - 3s 4ms/step\n",
            "Look Back: 2\n",
            "MSE: 480.03869881506176\n",
            "MAE: 15.691284214928212\n",
            "MAPE: 1.3956345334605473\n",
            "RMSE: 21.909785457987983\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "658/658 [==============================] - 23s 21ms/step - loss: 0.0089 - val_loss: 0.0019\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 13s 20ms/step - loss: 0.0012 - val_loss: 5.8965e-04\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 12s 19ms/step - loss: 5.2675e-04 - val_loss: 3.8716e-04\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 11s 17ms/step - loss: 4.2970e-04 - val_loss: 4.0378e-04\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 13s 20ms/step - loss: 3.8564e-04 - val_loss: 3.3486e-04\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 13s 20ms/step - loss: 3.7436e-04 - val_loss: 4.2377e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 10s 16ms/step - loss: 3.5348e-04 - val_loss: 8.5786e-04\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 13s 19ms/step - loss: 3.3755e-04 - val_loss: 3.3426e-04\n",
            "Epoch 9/100\n",
            "658/658 [==============================] - 13s 19ms/step - loss: 3.2364e-04 - val_loss: 3.4549e-04\n",
            "Epoch 10/100\n",
            "658/658 [==============================] - 11s 16ms/step - loss: 3.1031e-04 - val_loss: 3.6764e-04\n",
            "Epoch 11/100\n",
            "658/658 [==============================] - 12s 19ms/step - loss: 3.0001e-04 - val_loss: 2.7401e-04\n",
            "Epoch 12/100\n",
            "658/658 [==============================] - 13s 20ms/step - loss: 2.8471e-04 - val_loss: 4.1625e-04\n",
            "Epoch 13/100\n",
            "658/658 [==============================] - 11s 17ms/step - loss: 2.7791e-04 - val_loss: 2.6921e-04\n",
            "Epoch 14/100\n",
            "658/658 [==============================] - 12s 19ms/step - loss: 2.6986e-04 - val_loss: 2.5724e-04\n",
            "Epoch 15/100\n",
            "658/658 [==============================] - 13s 20ms/step - loss: 2.6020e-04 - val_loss: 3.3968e-04\n",
            "Epoch 16/100\n",
            "658/658 [==============================] - 11s 17ms/step - loss: 2.5870e-04 - val_loss: 2.5620e-04\n",
            "Epoch 17/100\n",
            "658/658 [==============================] - 12s 18ms/step - loss: 2.5298e-04 - val_loss: 2.8348e-04\n",
            "Epoch 18/100\n",
            "658/658 [==============================] - 13s 20ms/step - loss: 2.4624e-04 - val_loss: 2.7089e-04\n",
            "Epoch 19/100\n",
            "658/658 [==============================] - 12s 18ms/step - loss: 2.4233e-04 - val_loss: 3.0948e-04\n",
            "Epoch 20/100\n",
            "658/658 [==============================] - 11s 17ms/step - loss: 2.4029e-04 - val_loss: 5.4702e-04\n",
            "Epoch 21/100\n",
            "658/658 [==============================] - 13s 20ms/step - loss: 2.3471e-04 - val_loss: 2.6716e-04\n",
            "274/274 [==============================] - 3s 4ms/step\n",
            "Look Back: 4\n",
            "MSE: 355.84152331454055\n",
            "MAE: 14.225672518659957\n",
            "MAPE: 1.291160743636674\n",
            "RMSE: 18.863762172868395\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "658/658 [==============================] - 26s 25ms/step - loss: 0.0097 - val_loss: 0.0016\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.0010 - val_loss: 4.6589e-04\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 14s 22ms/step - loss: 4.7445e-04 - val_loss: 3.8842e-04\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 13s 20ms/step - loss: 3.8668e-04 - val_loss: 3.0489e-04\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 14s 22ms/step - loss: 3.5591e-04 - val_loss: 2.8314e-04\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 3.2784e-04 - val_loss: 3.7813e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 3.1823e-04 - val_loss: 4.1288e-04\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 3.0292e-04 - val_loss: 2.3634e-04\n",
            "Epoch 9/100\n",
            "658/658 [==============================] - 13s 20ms/step - loss: 2.8574e-04 - val_loss: 2.5871e-04\n",
            "Epoch 10/100\n",
            "658/658 [==============================] - 14s 22ms/step - loss: 2.7271e-04 - val_loss: 2.5326e-04\n",
            "Epoch 11/100\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 2.6481e-04 - val_loss: 2.4574e-04\n",
            "Epoch 12/100\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 2.5872e-04 - val_loss: 2.1231e-04\n",
            "Epoch 13/100\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 2.4904e-04 - val_loss: 2.1834e-04\n",
            "Epoch 14/100\n",
            "658/658 [==============================] - 13s 20ms/step - loss: 2.4155e-04 - val_loss: 3.3801e-04\n",
            "Epoch 15/100\n",
            "658/658 [==============================] - 14s 21ms/step - loss: 2.3680e-04 - val_loss: 2.0458e-04\n",
            "Epoch 16/100\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 2.3362e-04 - val_loss: 2.5220e-04\n",
            "Epoch 17/100\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 2.2398e-04 - val_loss: 2.8557e-04\n",
            "Epoch 18/100\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 2.1903e-04 - val_loss: 1.7079e-04\n",
            "Epoch 19/100\n",
            "658/658 [==============================] - 14s 21ms/step - loss: 2.1246e-04 - val_loss: 1.6828e-04\n",
            "Epoch 20/100\n",
            "658/658 [==============================] - 13s 20ms/step - loss: 2.0778e-04 - val_loss: 2.0823e-04\n",
            "Epoch 21/100\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 2.0168e-04 - val_loss: 2.0731e-04\n",
            "Epoch 22/100\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 2.0063e-04 - val_loss: 2.1347e-04\n",
            "Epoch 23/100\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 1.9274e-04 - val_loss: 2.1520e-04\n",
            "Epoch 24/100\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 1.8868e-04 - val_loss: 1.7355e-04\n",
            "274/274 [==============================] - 3s 5ms/step\n",
            "Look Back: 6\n",
            "MSE: 292.99698271155535\n",
            "MAE: 12.390535489955552\n",
            "MAPE: 1.1014266473968197\n",
            "RMSE: 17.11715463246025\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "658/658 [==============================] - 30s 29ms/step - loss: 0.0094 - val_loss: 0.0027\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 18s 27ms/step - loss: 0.0013 - val_loss: 5.6022e-04\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 18s 27ms/step - loss: 4.9697e-04 - val_loss: 0.0010\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 18s 27ms/step - loss: 3.8414e-04 - val_loss: 3.1367e-04\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 3.2689e-04 - val_loss: 4.1499e-04\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 2.9801e-04 - val_loss: 2.1027e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 2.5576e-04 - val_loss: 3.7030e-04\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 2.3742e-04 - val_loss: 2.4744e-04\n",
            "Epoch 9/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 2.3015e-04 - val_loss: 1.6000e-04\n",
            "Epoch 10/100\n",
            "658/658 [==============================] - 18s 28ms/step - loss: 2.0904e-04 - val_loss: 1.5985e-04\n",
            "Epoch 11/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 2.0855e-04 - val_loss: 1.8064e-04\n",
            "Epoch 12/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 1.9679e-04 - val_loss: 1.6692e-04\n",
            "Epoch 13/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 1.9463e-04 - val_loss: 1.6557e-04\n",
            "Epoch 14/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 1.8593e-04 - val_loss: 2.0426e-04\n",
            "Epoch 15/100\n",
            "658/658 [==============================] - 17s 26ms/step - loss: 1.7848e-04 - val_loss: 2.3396e-04\n",
            "274/274 [==============================] - 3s 6ms/step\n",
            "Look Back: 8\n",
            "MSE: 251.87178352422765\n",
            "MAE: 11.760889105734732\n",
            "MAPE: 1.0535685220142565\n",
            "RMSE: 15.870468913180469\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "658/658 [==============================] - 33s 33ms/step - loss: 0.0095 - val_loss: 0.0021\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 20s 31ms/step - loss: 0.0011 - val_loss: 4.4422e-04\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 20s 31ms/step - loss: 4.7769e-04 - val_loss: 3.3164e-04\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 32s 48ms/step - loss: 3.2815e-04 - val_loss: 2.2670e-04\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 20s 31ms/step - loss: 2.9519e-04 - val_loss: 2.8827e-04\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 20s 31ms/step - loss: 2.5022e-04 - val_loss: 2.4997e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 20s 31ms/step - loss: 2.3326e-04 - val_loss: 2.0160e-04\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 2.2242e-04 - val_loss: 2.3670e-04\n",
            "Epoch 9/100\n",
            "658/658 [==============================] - 23s 35ms/step - loss: 2.0534e-04 - val_loss: 1.5429e-04\n",
            "Epoch 10/100\n",
            "658/658 [==============================] - 20s 31ms/step - loss: 1.9690e-04 - val_loss: 3.0476e-04\n",
            "Epoch 11/100\n",
            "658/658 [==============================] - 20s 31ms/step - loss: 1.8703e-04 - val_loss: 1.8192e-04\n",
            "Epoch 12/100\n",
            "658/658 [==============================] - 20s 31ms/step - loss: 1.7872e-04 - val_loss: 1.4482e-04\n",
            "Epoch 13/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 1.7539e-04 - val_loss: 1.8599e-04\n",
            "Epoch 14/100\n",
            "658/658 [==============================] - 22s 33ms/step - loss: 1.7243e-04 - val_loss: 1.5167e-04\n",
            "Epoch 15/100\n",
            "658/658 [==============================] - 21s 32ms/step - loss: 1.6405e-04 - val_loss: 2.4026e-04\n",
            "Epoch 16/100\n",
            "658/658 [==============================] - 20s 31ms/step - loss: 1.5872e-04 - val_loss: 5.6467e-04\n",
            "Epoch 17/100\n",
            "658/658 [==============================] - 20s 31ms/step - loss: 1.5431e-04 - val_loss: 1.8193e-04\n",
            "274/274 [==============================] - 3s 7ms/step\n",
            "Look Back: 10\n",
            "MSE: 207.18226520235706\n",
            "MAE: 10.715029034873078\n",
            "MAPE: 0.9622373747923394\n",
            "RMSE: 14.393827329878494\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "658/658 [==============================] - 34s 37ms/step - loss: 0.0083 - val_loss: 0.0033\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 25s 39ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 23s 35ms/step - loss: 6.3195e-04 - val_loss: 0.0011\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 23s 35ms/step - loss: 3.9426e-04 - val_loss: 2.5769e-04\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 25s 38ms/step - loss: 2.8018e-04 - val_loss: 2.2488e-04\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 23s 35ms/step - loss: 2.4457e-04 - val_loss: 6.3909e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 23s 35ms/step - loss: 2.2750e-04 - val_loss: 2.1254e-04\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 25s 37ms/step - loss: 2.0716e-04 - val_loss: 2.3957e-04\n",
            "Epoch 9/100\n",
            "658/658 [==============================] - 24s 36ms/step - loss: 1.8947e-04 - val_loss: 2.5075e-04\n",
            "Epoch 10/100\n",
            "658/658 [==============================] - 23s 35ms/step - loss: 1.9208e-04 - val_loss: 2.3271e-04\n",
            "Epoch 11/100\n",
            "658/658 [==============================] - 25s 38ms/step - loss: 1.7741e-04 - val_loss: 1.5825e-04\n",
            "Epoch 12/100\n",
            "658/658 [==============================] - 24s 36ms/step - loss: 1.6627e-04 - val_loss: 1.8213e-04\n",
            "Epoch 13/100\n",
            "658/658 [==============================] - 23s 35ms/step - loss: 1.6723e-04 - val_loss: 1.7743e-04\n",
            "Epoch 14/100\n",
            "658/658 [==============================] - 24s 37ms/step - loss: 1.6002e-04 - val_loss: 1.4673e-04\n",
            "Epoch 15/100\n",
            "658/658 [==============================] - 24s 36ms/step - loss: 1.5524e-04 - val_loss: 2.7472e-04\n",
            "Epoch 16/100\n",
            "658/658 [==============================] - 23s 35ms/step - loss: 1.5418e-04 - val_loss: 1.6248e-04\n",
            "Epoch 17/100\n",
            "658/658 [==============================] - 24s 36ms/step - loss: 1.4742e-04 - val_loss: 1.4584e-04\n",
            "Epoch 18/100\n",
            "658/658 [==============================] - 24s 37ms/step - loss: 1.4015e-04 - val_loss: 1.4401e-04\n",
            "Epoch 19/100\n",
            "658/658 [==============================] - 23s 35ms/step - loss: 1.3790e-04 - val_loss: 1.9325e-04\n",
            "Epoch 20/100\n",
            "658/658 [==============================] - 23s 35ms/step - loss: 1.3711e-04 - val_loss: 1.7633e-04\n",
            "Epoch 21/100\n",
            "658/658 [==============================] - 25s 38ms/step - loss: 1.3232e-04 - val_loss: 2.6496e-04\n",
            "Epoch 22/100\n",
            "658/658 [==============================] - 23s 35ms/step - loss: 1.2969e-04 - val_loss: 9.5415e-04\n",
            "Epoch 23/100\n",
            "658/658 [==============================] - 23s 35ms/step - loss: 1.3163e-04 - val_loss: 1.5896e-04\n",
            "274/274 [==============================] - 4s 8ms/step\n",
            "Look Back: 12\n",
            "MSE: 183.74561647489307\n",
            "MAE: 9.98246968958471\n",
            "MAPE: 0.8924141848550304\n",
            "RMSE: 13.555280022002242\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "658/658 [==============================] - 38s 41ms/step - loss: 0.0081 - val_loss: 0.0029\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 28s 42ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 25s 38ms/step - loss: 8.7195e-04 - val_loss: 0.0015\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 27s 40ms/step - loss: 4.8960e-04 - val_loss: 4.9237e-04\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 26s 39ms/step - loss: 3.1948e-04 - val_loss: 6.7040e-04\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 26s 39ms/step - loss: 2.3829e-04 - val_loss: 5.9805e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 27s 41ms/step - loss: 2.2890e-04 - val_loss: 3.7485e-04\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 26s 40ms/step - loss: 2.2386e-04 - val_loss: 1.8210e-04\n",
            "Epoch 9/100\n",
            "658/658 [==============================] - 27s 41ms/step - loss: 1.9870e-04 - val_loss: 5.5004e-04\n",
            "Epoch 10/100\n",
            "658/658 [==============================] - 25s 38ms/step - loss: 1.9148e-04 - val_loss: 1.9920e-04\n",
            "Epoch 11/100\n",
            "658/658 [==============================] - 28s 42ms/step - loss: 1.8858e-04 - val_loss: 1.6053e-04\n",
            "Epoch 12/100\n",
            "658/658 [==============================] - 25s 38ms/step - loss: 1.8330e-04 - val_loss: 1.5268e-04\n",
            "Epoch 13/100\n",
            "658/658 [==============================] - 28s 43ms/step - loss: 1.7184e-04 - val_loss: 2.1868e-04\n",
            "Epoch 14/100\n",
            "658/658 [==============================] - 25s 38ms/step - loss: 1.6940e-04 - val_loss: 3.7411e-04\n",
            "Epoch 15/100\n",
            "658/658 [==============================] - 28s 42ms/step - loss: 1.5858e-04 - val_loss: 1.4369e-04\n",
            "Epoch 16/100\n",
            "658/658 [==============================] - 25s 38ms/step - loss: 1.5580e-04 - val_loss: 1.5358e-04\n",
            "Epoch 17/100\n",
            "658/658 [==============================] - 27s 41ms/step - loss: 1.4952e-04 - val_loss: 1.3520e-04\n",
            "Epoch 18/100\n",
            "658/658 [==============================] - 25s 39ms/step - loss: 1.5121e-04 - val_loss: 2.5483e-04\n",
            "Epoch 19/100\n",
            "658/658 [==============================] - 26s 40ms/step - loss: 1.4392e-04 - val_loss: 1.5147e-04\n",
            "Epoch 20/100\n",
            "658/658 [==============================] - 26s 40ms/step - loss: 1.3731e-04 - val_loss: 2.1220e-04\n",
            "Epoch 21/100\n",
            "658/658 [==============================] - 26s 40ms/step - loss: 1.3653e-04 - val_loss: 1.7650e-04\n",
            "Epoch 22/100\n",
            "658/658 [==============================] - 27s 41ms/step - loss: 1.3581e-04 - val_loss: 1.2645e-04\n",
            "Epoch 23/100\n",
            "658/658 [==============================] - 25s 38ms/step - loss: 1.2829e-04 - val_loss: 1.5650e-04\n",
            "Epoch 24/100\n",
            "658/658 [==============================] - 28s 42ms/step - loss: 1.2695e-04 - val_loss: 1.5789e-04\n",
            "Epoch 25/100\n",
            "658/658 [==============================] - 25s 38ms/step - loss: 1.2718e-04 - val_loss: 1.2267e-04\n",
            "Epoch 26/100\n",
            "658/658 [==============================] - 28s 43ms/step - loss: 1.1969e-04 - val_loss: 2.7466e-04\n",
            "Epoch 27/100\n",
            "658/658 [==============================] - 25s 38ms/step - loss: 1.1851e-04 - val_loss: 1.3298e-04\n",
            "Epoch 28/100\n",
            "658/658 [==============================] - 28s 42ms/step - loss: 1.1698e-04 - val_loss: 3.4520e-04\n",
            "Epoch 29/100\n",
            "658/658 [==============================] - 25s 38ms/step - loss: 1.1593e-04 - val_loss: 1.1242e-04\n",
            "Epoch 30/100\n",
            "658/658 [==============================] - 27s 42ms/step - loss: 1.1017e-04 - val_loss: 2.6899e-04\n",
            "Epoch 31/100\n",
            "658/658 [==============================] - 25s 39ms/step - loss: 1.1478e-04 - val_loss: 1.0280e-04\n",
            "Epoch 32/100\n",
            "658/658 [==============================] - 26s 40ms/step - loss: 1.0808e-04 - val_loss: 1.1008e-04\n",
            "Epoch 33/100\n",
            "658/658 [==============================] - 26s 40ms/step - loss: 1.0648e-04 - val_loss: 1.0651e-04\n",
            "Epoch 34/100\n",
            "658/658 [==============================] - 25s 38ms/step - loss: 1.0735e-04 - val_loss: 1.5133e-04\n",
            "Epoch 35/100\n",
            "658/658 [==============================] - 28s 42ms/step - loss: 1.0478e-04 - val_loss: 1.7621e-04\n",
            "Epoch 36/100\n",
            "658/658 [==============================] - 25s 38ms/step - loss: 1.0455e-04 - val_loss: 8.7418e-05\n",
            "Epoch 37/100\n",
            "658/658 [==============================] - 28s 42ms/step - loss: 1.0314e-04 - val_loss: 9.3288e-05\n",
            "Epoch 38/100\n",
            "658/658 [==============================] - 25s 38ms/step - loss: 1.0080e-04 - val_loss: 1.0630e-04\n",
            "Epoch 39/100\n",
            "658/658 [==============================] - 27s 41ms/step - loss: 1.0083e-04 - val_loss: 1.3431e-04\n",
            "Epoch 40/100\n",
            "658/658 [==============================] - 26s 39ms/step - loss: 9.8935e-05 - val_loss: 9.8762e-05\n",
            "Epoch 41/100\n",
            "658/658 [==============================] - 26s 40ms/step - loss: 1.0006e-04 - val_loss: 9.0550e-05\n",
            "274/274 [==============================] - 4s 10ms/step\n",
            "Look Back: 14\n",
            "MSE: 138.747991253568\n",
            "MAE: 8.491351184482141\n",
            "MAPE: 0.7657169037302552\n",
            "RMSE: 11.779133722543776\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "658/658 [==============================] - 42s 49ms/step - loss: 0.0085 - val_loss: 0.0106\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 28s 42ms/step - loss: 0.0024 - val_loss: 0.0047\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 31s 47ms/step - loss: 0.0010 - val_loss: 6.7555e-04\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 30s 46ms/step - loss: 5.1761e-04 - val_loss: 7.8446e-04\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 28s 43ms/step - loss: 3.1470e-04 - val_loss: 2.7000e-04\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 31s 47ms/step - loss: 2.7174e-04 - val_loss: 7.1827e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 29s 44ms/step - loss: 2.4358e-04 - val_loss: 0.0020\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 30s 45ms/step - loss: 2.2544e-04 - val_loss: 4.0014e-04\n",
            "Epoch 9/100\n",
            "658/658 [==============================] - 31s 47ms/step - loss: 2.1020e-04 - val_loss: 3.0889e-04\n",
            "Epoch 10/100\n",
            "658/658 [==============================] - 29s 44ms/step - loss: 1.9277e-04 - val_loss: 1.6383e-04\n",
            "Epoch 11/100\n",
            "658/658 [==============================] - 30s 46ms/step - loss: 1.8551e-04 - val_loss: 1.4354e-04\n",
            "Epoch 12/100\n",
            "658/658 [==============================] - 31s 47ms/step - loss: 1.7586e-04 - val_loss: 2.7671e-04\n",
            "Epoch 13/100\n",
            "658/658 [==============================] - 28s 42ms/step - loss: 1.7157e-04 - val_loss: 1.5637e-04\n",
            "Epoch 14/100\n",
            "658/658 [==============================] - 31s 47ms/step - loss: 1.6142e-04 - val_loss: 7.0325e-04\n",
            "Epoch 15/100\n",
            "658/658 [==============================] - 29s 45ms/step - loss: 1.5510e-04 - val_loss: 4.4944e-04\n",
            "Epoch 16/100\n",
            "658/658 [==============================] - 29s 44ms/step - loss: 1.5203e-04 - val_loss: 4.2833e-04\n",
            "274/274 [==============================] - 6s 12ms/step\n",
            "Look Back: 16\n",
            "MSE: 213.1708018835811\n",
            "MAE: 10.866750468401431\n",
            "MAPE: 0.9562091714732367\n",
            "RMSE: 14.6003699228335\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "658/658 [==============================] - 45s 53ms/step - loss: 0.0090 - val_loss: 0.0054\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 33s 50ms/step - loss: 0.0028 - val_loss: 0.0038\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 31s 48ms/step - loss: 0.0012 - val_loss: 0.0020\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 32s 49ms/step - loss: 6.4132e-04 - val_loss: 0.0027\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 34s 51ms/step - loss: 4.1335e-04 - val_loss: 0.0015\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 34s 51ms/step - loss: 3.0176e-04 - val_loss: 3.0477e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 33s 50ms/step - loss: 2.5622e-04 - val_loss: 4.0459e-04\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 32s 48ms/step - loss: 2.3296e-04 - val_loss: 2.2449e-04\n",
            "Epoch 9/100\n",
            "658/658 [==============================] - 32s 49ms/step - loss: 2.1925e-04 - val_loss: 2.3798e-04\n",
            "Epoch 10/100\n",
            "658/658 [==============================] - 34s 51ms/step - loss: 2.1169e-04 - val_loss: 5.1952e-04\n",
            "Epoch 11/100\n",
            "658/658 [==============================] - 34s 51ms/step - loss: 2.0167e-04 - val_loss: 3.8083e-04\n",
            "Epoch 12/100\n",
            "658/658 [==============================] - 33s 50ms/step - loss: 1.9255e-04 - val_loss: 1.8448e-04\n",
            "Epoch 13/100\n",
            "658/658 [==============================] - 31s 47ms/step - loss: 1.8562e-04 - val_loss: 1.4705e-04\n",
            "Epoch 14/100\n",
            "658/658 [==============================] - 32s 49ms/step - loss: 1.7382e-04 - val_loss: 4.1528e-04\n",
            "Epoch 15/100\n",
            "658/658 [==============================] - 34s 51ms/step - loss: 1.6952e-04 - val_loss: 2.7974e-04\n",
            "Epoch 16/100\n",
            "658/658 [==============================] - 33s 51ms/step - loss: 1.6440e-04 - val_loss: 2.7754e-04\n",
            "Epoch 17/100\n",
            "658/658 [==============================] - 33s 50ms/step - loss: 1.5720e-04 - val_loss: 1.8691e-04\n",
            "Epoch 18/100\n",
            "658/658 [==============================] - 31s 48ms/step - loss: 1.5594e-04 - val_loss: 1.8399e-04\n",
            "274/274 [==============================] - 5s 12ms/step\n",
            "Look Back: 18\n",
            "MSE: 220.96859575026156\n",
            "MAE: 11.118322150335372\n",
            "MAPE: 1.0020998622147743\n",
            "RMSE: 14.865012470572017\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "658/658 [==============================] - 47s 56ms/step - loss: 0.0090 - val_loss: 0.0049\n",
            "Epoch 2/100\n",
            "658/658 [==============================] - 37s 57ms/step - loss: 0.0021 - val_loss: 0.0056\n",
            "Epoch 3/100\n",
            "658/658 [==============================] - 35s 54ms/step - loss: 9.1703e-04 - val_loss: 9.4840e-04\n",
            "Epoch 4/100\n",
            "658/658 [==============================] - 35s 53ms/step - loss: 6.0812e-04 - val_loss: 4.7876e-04\n",
            "Epoch 5/100\n",
            "658/658 [==============================] - 34s 52ms/step - loss: 3.9258e-04 - val_loss: 0.0015\n",
            "Epoch 6/100\n",
            "658/658 [==============================] - 34s 52ms/step - loss: 2.9983e-04 - val_loss: 4.4425e-04\n",
            "Epoch 7/100\n",
            "658/658 [==============================] - 35s 52ms/step - loss: 2.3989e-04 - val_loss: 2.3003e-04\n",
            "Epoch 8/100\n",
            "658/658 [==============================] - 35s 53ms/step - loss: 2.2169e-04 - val_loss: 0.0033\n",
            "Epoch 9/100\n",
            "658/658 [==============================] - 35s 53ms/step - loss: 2.2422e-04 - val_loss: 0.0030\n",
            "Epoch 10/100\n",
            "658/658 [==============================] - 36s 54ms/step - loss: 2.1197e-04 - val_loss: 2.5426e-04\n",
            "Epoch 11/100\n",
            "658/658 [==============================] - 36s 54ms/step - loss: 1.8701e-04 - val_loss: 1.6090e-04\n",
            "Epoch 12/100\n",
            "658/658 [==============================] - 36s 54ms/step - loss: 1.8620e-04 - val_loss: 1.7568e-04\n",
            "Epoch 13/100\n",
            "658/658 [==============================] - 36s 54ms/step - loss: 1.7434e-04 - val_loss: 8.1928e-04\n",
            "Epoch 14/100\n",
            "658/658 [==============================] - 36s 54ms/step - loss: 1.6917e-04 - val_loss: 1.7621e-04\n",
            "Epoch 15/100\n",
            "658/658 [==============================] - 35s 54ms/step - loss: 1.5888e-04 - val_loss: 6.6138e-04\n",
            "Epoch 16/100\n",
            "658/658 [==============================] - 35s 54ms/step - loss: 1.4991e-04 - val_loss: 8.6535e-04\n",
            "274/274 [==============================] - 5s 12ms/step\n",
            "Look Back: 20\n",
            "MSE: 273.09981239385326\n",
            "MAE: 12.459133987359182\n",
            "MAPE: 1.0964620627856845\n",
            "RMSE: 16.525731826271816\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "657/657 [==============================] - 44s 52ms/step - loss: 0.0091 - val_loss: 0.0024\n",
            "Epoch 2/100\n",
            "657/657 [==============================] - 29s 45ms/step - loss: 0.0018 - val_loss: 0.0010\n",
            "Epoch 3/100\n",
            "657/657 [==============================] - 32s 49ms/step - loss: 9.6104e-04 - val_loss: 5.8064e-04\n",
            "Epoch 4/100\n",
            "657/657 [==============================] - 32s 49ms/step - loss: 6.1084e-04 - val_loss: 3.7151e-04\n",
            "Epoch 5/100\n",
            "657/657 [==============================] - 30s 45ms/step - loss: 3.8476e-04 - val_loss: 2.3763e-04\n",
            "Epoch 6/100\n",
            "657/657 [==============================] - 32s 48ms/step - loss: 2.8006e-04 - val_loss: 1.9313e-04\n",
            "Epoch 7/100\n",
            "657/657 [==============================] - 33s 49ms/step - loss: 2.4088e-04 - val_loss: 1.6254e-04\n",
            "Epoch 8/100\n",
            "657/657 [==============================] - 31s 48ms/step - loss: 2.1393e-04 - val_loss: 2.4962e-04\n",
            "Epoch 9/100\n",
            "657/657 [==============================] - 30s 45ms/step - loss: 2.0457e-04 - val_loss: 1.9078e-04\n",
            "Epoch 10/100\n",
            "657/657 [==============================] - 33s 50ms/step - loss: 1.9370e-04 - val_loss: 1.6023e-04\n",
            "Epoch 11/100\n",
            "657/657 [==============================] - 32s 49ms/step - loss: 1.8933e-04 - val_loss: 1.5337e-04\n",
            "Epoch 12/100\n",
            "657/657 [==============================] - 30s 45ms/step - loss: 1.8258e-04 - val_loss: 1.5846e-04\n",
            "Epoch 13/100\n",
            "657/657 [==============================] - 32s 48ms/step - loss: 1.7692e-04 - val_loss: 1.7836e-04\n",
            "Epoch 14/100\n",
            "657/657 [==============================] - 33s 50ms/step - loss: 1.6452e-04 - val_loss: 1.4661e-04\n",
            "Epoch 15/100\n",
            "657/657 [==============================] - 31s 47ms/step - loss: 1.6959e-04 - val_loss: 1.7828e-04\n",
            "Epoch 16/100\n",
            "657/657 [==============================] - 31s 47ms/step - loss: 1.5685e-04 - val_loss: 1.8921e-04\n",
            "Epoch 17/100\n",
            "657/657 [==============================] - 33s 50ms/step - loss: 1.5778e-04 - val_loss: 1.6209e-04\n",
            "Epoch 18/100\n",
            "657/657 [==============================] - 34s 52ms/step - loss: 1.5116e-04 - val_loss: 1.5794e-04\n",
            "Epoch 19/100\n",
            "657/657 [==============================] - 31s 47ms/step - loss: 1.4855e-04 - val_loss: 1.3689e-04\n",
            "Epoch 20/100\n",
            "657/657 [==============================] - 30s 46ms/step - loss: 1.4723e-04 - val_loss: 1.4760e-04\n",
            "Epoch 21/100\n",
            "657/657 [==============================] - 32s 49ms/step - loss: 1.3684e-04 - val_loss: 1.4297e-04\n",
            "Epoch 22/100\n",
            "657/657 [==============================] - 34s 52ms/step - loss: 1.3473e-04 - val_loss: 1.1334e-04\n",
            "Epoch 23/100\n",
            "657/657 [==============================] - 32s 49ms/step - loss: 1.2700e-04 - val_loss: 1.1558e-04\n",
            "Epoch 24/100\n",
            "657/657 [==============================] - 29s 45ms/step - loss: 1.2491e-04 - val_loss: 1.4199e-04\n",
            "Epoch 25/100\n",
            "657/657 [==============================] - 32s 49ms/step - loss: 1.2137e-04 - val_loss: 1.4406e-04\n",
            "Epoch 26/100\n",
            "657/657 [==============================] - 32s 49ms/step - loss: 1.2203e-04 - val_loss: 1.0621e-04\n",
            "Epoch 27/100\n",
            "657/657 [==============================] - 30s 46ms/step - loss: 1.1838e-04 - val_loss: 1.1537e-04\n",
            "Epoch 28/100\n",
            "657/657 [==============================] - 31s 47ms/step - loss: 1.1650e-04 - val_loss: 1.7604e-04\n",
            "Epoch 29/100\n",
            "657/657 [==============================] - 33s 49ms/step - loss: 1.1489e-04 - val_loss: 1.1053e-04\n",
            "Epoch 30/100\n",
            "657/657 [==============================] - 31s 47ms/step - loss: 1.1035e-04 - val_loss: 1.2757e-04\n",
            "Epoch 31/100\n",
            "657/657 [==============================] - 30s 46ms/step - loss: 1.1334e-04 - val_loss: 1.2673e-04\n",
            "274/274 [==============================] - 7s 17ms/step\n",
            "Look Back: 22\n",
            "MSE: 177.81421657572793\n",
            "MAE: 9.825493598096521\n",
            "MAPE: 0.8641922060115939\n",
            "RMSE: 13.334699718243675\n",
            "--------------------\n",
            "Epoch 1/100\n",
            "657/657 [==============================] - 53s 66ms/step - loss: 0.0092 - val_loss: 0.0035\n",
            "Epoch 2/100\n",
            "657/657 [==============================] - 40s 61ms/step - loss: 0.0028 - val_loss: 0.0022\n",
            "Epoch 3/100\n",
            "657/657 [==============================] - 40s 61ms/step - loss: 0.0016 - val_loss: 9.5774e-04\n",
            "Epoch 4/100\n",
            "657/657 [==============================] - 41s 62ms/step - loss: 8.5010e-04 - val_loss: 5.5763e-04\n",
            "Epoch 5/100\n",
            "657/657 [==============================] - 42s 63ms/step - loss: 5.6056e-04 - val_loss: 5.3315e-04\n",
            "Epoch 6/100\n",
            "657/657 [==============================] - 40s 61ms/step - loss: 3.7429e-04 - val_loss: 3.7015e-04\n",
            "Epoch 7/100\n",
            "657/657 [==============================] - 40s 61ms/step - loss: 2.7839e-04 - val_loss: 2.4625e-04\n",
            "Epoch 8/100\n",
            "657/657 [==============================] - 41s 62ms/step - loss: 2.4933e-04 - val_loss: 2.7554e-04\n",
            "Epoch 9/100\n",
            "657/657 [==============================] - 42s 64ms/step - loss: 2.3673e-04 - val_loss: 2.2076e-04\n",
            "Epoch 10/100\n",
            "657/657 [==============================] - 41s 62ms/step - loss: 2.1772e-04 - val_loss: 2.0076e-04\n",
            "Epoch 11/100\n",
            "657/657 [==============================] - 40s 61ms/step - loss: 2.0683e-04 - val_loss: 1.9480e-04\n",
            "Epoch 12/100\n",
            "657/657 [==============================] - 40s 61ms/step - loss: 2.0324e-04 - val_loss: 1.6043e-04\n",
            "Epoch 13/100\n",
            "657/657 [==============================] - 41s 63ms/step - loss: 1.8048e-04 - val_loss: 1.7085e-04\n",
            "Epoch 14/100\n",
            "657/657 [==============================] - 41s 63ms/step - loss: 1.7382e-04 - val_loss: 1.5591e-04\n",
            "Epoch 15/100\n",
            "657/657 [==============================] - 40s 61ms/step - loss: 1.6544e-04 - val_loss: 2.0756e-04\n",
            "Epoch 16/100\n",
            "657/657 [==============================] - 40s 61ms/step - loss: 1.6010e-04 - val_loss: 1.4324e-04\n",
            "Epoch 17/100\n",
            "657/657 [==============================] - 41s 62ms/step - loss: 1.5118e-04 - val_loss: 1.4939e-04\n",
            "Epoch 18/100\n",
            "657/657 [==============================] - 42s 64ms/step - loss: 1.4767e-04 - val_loss: 1.5332e-04\n",
            "Epoch 19/100\n",
            "657/657 [==============================] - 41s 62ms/step - loss: 1.4714e-04 - val_loss: 1.4592e-04\n",
            "Epoch 20/100\n",
            "657/657 [==============================] - 40s 61ms/step - loss: 1.4138e-04 - val_loss: 1.5042e-04\n",
            "Epoch 21/100\n",
            "657/657 [==============================] - 40s 61ms/step - loss: 1.3600e-04 - val_loss: 1.8125e-04\n",
            "274/274 [==============================] - 6s 15ms/step\n",
            "Look Back: 24\n",
            "MSE: 196.66814924092975\n",
            "MAE: 10.440559746564338\n",
            "MAPE: 0.9382138587162216\n",
            "RMSE: 14.023842171135902\n",
            "--------------------\n"
          ]
        }
      ]
    }
  ]
}